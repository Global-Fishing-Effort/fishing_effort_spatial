---
title: "FAO fishing effort project - Data wrangling - Spatial measures"
author: "Gage Clawson (IMAS)"
date: '`r format(Sys.time(), "%m/%d/%Y")`'
output: 
  pdf_document: 
    number_sections: yes
    toc: true
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

# Summary

Prep spatial measures we use to inform our model
 - EEZ regions
 - FAO regions
 - distance to short, port
 - bathymetry (depth)

```{r echo = FALSE}
# This chunk sets up default settings for all chunks below
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,fig.width = 7.5,fig.height = 5,dev = 'png',dpi=300)
```

```{r include=FALSE}
# Load all necessary packages
library(tidyverse)
library(sf)
library(glue)
library(rnaturalearth)
library(furrr)
library(countrycode)
library(terra)
library(data.table)
library(tictoc)
library(here)
library(furrr)
library(here)
library(mapview)
library(janitor)
library(raster)
library(fasterize)

setDTthreads(parallelly::availableCores())

options(scipen = 20)
# How many cores should we leave free on the system when we start running things in parallel?
free_cores <- 0
n_cores <- parallelly::availableCores() - free_cores

source(here("R/dir.R"))

data_directory <- rdsi_raw_dir


# Set ggplot theme for all plots
theme_set(theme_minimal() +
            theme(axis.title.y = element_text(angle = 0,vjust=0.5),
                  strip.background = element_blank(),
                  strip.text.y = element_text(angle=0),
                  strip.text.y.right = element_text(angle=0),
                  strip.text.y.left = element_text(angle=0),
                  panel.grid = element_blank(),
                  panel.background = element_blank(),
                  panel.grid.minor = element_blank(),
                  panel.grid.major = element_blank()))

# Create global land sf object for mapping
world_plotting <- ne_countries(scale = "small", returnclass = "sf")  %>%
  dplyr::select(geometry)

```

# Defining our global grid

```{r}
pixel_size <- 1

mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

# Read in data_grid, generated in data_wrangling.Rmd
# We will do spatial joining in Mollweide, for proper calculations
# Note that data grid still retains lat and lon columns, for joining with non-spatial tibbles
# For Mollweide, always wrap around dateline, then transform, then calculate areas at end
data_grid <- data.table::fread(here("data/model_features/global_grid.csv"))%>%
  st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 
```

# Bathymetry, distance from shore, and distance to port (static)

GFW has spatial static measures at 0.01x0.01 degree resolution for bathymetry, distance from shore, and distance to port, all in meters (m). Distance to port is the distance to the closest port as defined by [GFW's port database and algorithm](https://globalfishingwatch.org/datasets-and-code-anchorages/). For each of our `r pixel_size`x`r pixel_size` degree pixels, we will take the average value for these static measures.

```{r}

bathymetry_data <- rast(file.path(data_directory, "global_fishing_watch/bathymetry/bathymetry.tif")) 

bathymetry_rast <- aggregate(bathymetry_data, fact = 60, fun = "mean")

bathymetry <- bathymetry_rast %>%
  as.data.frame(., xy = TRUE) %>% 
  rename(lon = x, lat = y, elevation_m = bathymetry) %>%
  mutate(
    lat = floor(lat / pixel_size) * pixel_size,
    lon = floor(lon / pixel_size) * pixel_size
  ) %>%
  filter(elevation_m <= 0) %>%
   group_by(lon, lat) %>%
  summarize(elevation_m = mean(elevation_m, na.rm = TRUE), .groups = "drop")

# test <- bathymetry %>%
#   rast(., type = "xyz")
  
write.csv(bathymetry, file.path(data_directory, "global_fishing_watch/bathymetry/bathymetry_0.5.csv"), row.names = FALSE)

distance_from_port_data <- rast(file.path(data_directory, "global_fishing_watch/distance_from_port/distance-from-port-v1.tiff")) 

distance_from_port <- aggregate(distance_from_port_data, fact = 50, fun = "mean") %>%
  as.data.frame(., xy=TRUE) %>%
  rename(lon = x, lat = y, distance_from_port_m = `distance-from-port-v1`) %>%
    mutate(
    lat = floor(lat / pixel_size) * pixel_size,
    lon = floor(lon / pixel_size) * pixel_size
  ) %>%
   group_by(lon, lat) %>%
  summarize(distance_from_port_m = mean(distance_from_port_m, na.rm = TRUE), .groups = "drop")
  
write.csv(distance_from_port, file.path(data_directory, "global_fishing_watch/distance_from_port/distance_from_port_0.5.csv"), row.names = FALSE)

distance_from_shore_data <- rast(file.path(data_directory, "global_fishing_watch/distance_from_shore/distance-from-shore.tif")) 

distance_from_shore <- aggregate(distance_from_shore_data, fact = 50, fun = "mean") %>%
  as.data.frame(.,  xy = TRUE) %>%
    rename(lon = x, lat = y, distance_from_shore_m = `distance-from-shore`) %>%
      mutate(
    lat = floor(lat / pixel_size) * pixel_size,
    lon = floor(lon / pixel_size) * pixel_size
  ) %>%
   group_by(lon, lat) %>%
  summarize(distance_from_shore_m = mean(distance_from_shore_m, na.rm = TRUE), .groups = "drop")

  write.csv(distance_from_shore, file.path(data_directory, "global_fishing_watch/distance_from_shore/distance_from_shore_0.5.csv"), row.names = FALSE)


  # Read in cached spatial measures data, add data_grid info and make into sf
static_spatial_measures <- bathymetry %>%
  full_join(distance_from_port, by = c("lat", "lon")) %>%
  full_join(distance_from_shore, by = c("lat", "lon")) %>% 
  inner_join(data_grid, by = c("lat", "lon")) %>% 
    # For some nearshore areas, replace NA depth with 0
  mutate(elevation_m = ifelse(is.na(elevation_m),
                              0,
                              elevation_m))

# test <- static_spatial_measures %>%
#   dplyr::select(lon, lat, distance_from_port_m) %>%
#   rast(., type = "xyz")
# plot(test)
  

static_spatial_measures %>%
  dplyr::select(-geometry_wkt) %>%
  data.table::fwrite(here::here("data/model_features/gfw_static_spatial_measures.csv"))

```


# Determine EEZ of each cell 

Use Marine Region's [Maritime Boundaries Geodatabase: Maritime Boundaries and Exclusive Economic Zones (200NM), version 12]

```{r}
global_grid <- read.csv(here("data/model_features/global_grid.csv"))
eezs <- st_read(file.path(rdsi_raw_dir, "marine_regions/World_EEZ_v12_20231025"), layer = 'eez_v12')
world_shp <- sf::st_as_sf(maps::map("world", plot = FALSE, fill = TRUE))

grid <- data_grid %>%
  st_drop_geometry() %>%
  dplyr::select(lon, lat, pixel_id) %>% 
  rast(., type = "xyz") 

eez_rast <- rast(fasterize::fasterize(eezs, raster(grid), field = "MRGID_SOV1"))
eez_rast

eez_rast[is.na(eez_rast)] <- 99999 # save a value high seas, not if sure necessary
eez_rast <- mask(eez_rast, vect(world_shp), inverse = TRUE) # mask out any land 
eez_rast[is.na(eez_rast)] <- 999999 # save a value for land, not sure if necessary


writeRaster(eez_rast, here("data/model_features/eez/eez_id_rast_0.5.tif"), overwrite = TRUE)

## get x, y lookup table so we can join to the raw mmsi data when saving and have the EEZ id already saved in the csv 


eez_lookup <- eez_rast %>%
  as.data.frame(xy = TRUE)

eez_check <- eez_lookup %>%
  mutate(x_int = floor(x), y_int = floor(y)) %>%  # extract integer part of x and y
  group_by(x_int, y_int) %>%
  summarise(x_unique_decimals = n_distinct(x),
            y_unique_decimals = n_distinct(y)) %>%
  ungroup()

eez_lookup_fin <- eez_lookup %>%
  dplyr::select(lon = x, lat = y, eez_id = layer) %>%
  left_join(global_grid) %>% 
  dplyr::select(pixel_id, eez_id)
  

write.csv(eez_lookup_fin, here("data/model_features/eez/eez.csv"), row.names = FALSE)

eez_lookup_ids <- eezs %>% 
  st_drop_geometry() %>%
  dplyr::distinct(ISO_SOV1, MRGID_SOV1) %>%
  add_row(ISO_SOV1 = "Land", MRGID_SOV1 = 999999) %>%
  add_row(ISO_SOV1 = "High seas", MRGID_SOV1 = 99999)

write.csv(eez_lookup_ids, here("data/model_features/deg_1_x_1/eez/eez_lookup.csv"), row.names = FALSE)

```


# Determine FAO region of each cell 
https://data.apps.fao.org/map/catalog/srv/eng/catalog.search#/metadata/ac02a460-da52-11dc-9d70-0017f293bd28d

```{r}

fao <- st_read(file.path(rdsi_raw_dir, "fao/FAO_AREAS_CWP")) %>%
  filter(F_LEVEL == "MAJOR") %>%
  mutate(F_AREA = as.numeric(F_AREA))
test <- fao %>% 
  st_drop_geometry()
world_shp <- sf::st_as_sf(maps::map("world", plot = FALSE, fill = TRUE))

fao_major_ids <- fao %>% 
  st_drop_geometry() %>%
  distinct(fao_id = F_AREA, NAME_EN, OCEAN) %>%
  clean_names()

write.csv(fao_major_ids, here("data/model_features/fao/fao_major_ids.csv"), row.names = FALSE)

grid <- data_grid %>%
  st_drop_geometry() %>%
  dplyr::select(lon, lat, pixel_id) %>% 
  rast(., type = "xyz") 

fao_rast <- rast(fasterize::fasterize(fao, raster(grid), field = "F_AREA"))
fao_rast


writeRaster(fao_rast, here("data/model_features/fao/fao_id_rast_0.5.tif"), overwrite = TRUE)

## get x, y lookup table so we can join to the raw mmsi data when saving and have the EEZ id already saved in the csv 


fao_lookup <- fao_rast %>%
  as.data.frame(xy = TRUE)


fao_lookup_fin <- fao_lookup %>%
  dplyr::select(lon = x, lat = y, fao_id = layer) %>%
  left_join(global_grid) %>% 
  dplyr::select(pixel_id, fao_id)
  

write.csv(fao_lookup_fin, here("data/model_features/fao/fao.csv"), row.names = FALSE)

```

# Determine if cell is mesopelagic zone or not 

Use Marine Region's [Mesopelagic ecoregions of the world's oceans](https://www.sciencedirect.com/science/article/pii/S0967063717301437?via%3Dihub#ack0005)

 - NOTE: 18/12/2024 - need to rerun this. Currently we are getting cells which have multiple meso regions in them for some reason. We only want 1 meso region per cell. 
  - maybe there is a way to rasterize the same way we do with the EEZ and FAO (see code chunks below)


```{r}
meso <- st_read(glue("{data_directory}/marine_regions/mesopelagiczones/")) %>%
  clean_names()

meso_ids <- meso %>%
  st_drop_geometry() %>%
  dplyr::select(provid, meso_region = provname)

write.csv(meso_ids, here("data/model_features/mesopelagiczones/mesopelagic_zones_ids.csv"), row.names = FALSE)

 grid <- data_grid %>%
  st_drop_geometry() %>%
  dplyr::select(lon, lat, pixel_id) %>% 
  rast(., type = "xyz") 
 
meso_rast <- rast(fasterize::fasterize(meso, raster(grid), field = "provid"))


writeRaster(meso_rast, here("data/model_features/mesopelagiczones/meso_id_rast.tif"), overwrite = TRUE)

## get x, y lookup table so we can join to the raw mmsi data when saving and have the EEZ id already saved in the csv 


meso_lookup <- meso_rast %>%
  as.data.frame(xy = TRUE)


meso_lookup_id <- meso_lookup %>%
  dplyr::select(lon = x, lat = y, provid = layer) %>%
  left_join(data_grid) %>% 
  dplyr::select(pixel_id, provid)

test <- meso_lookup_id %>%
  group_by(pixel_id) %>%
  summarise(n_distinct(provid)) # ok cool, seems to have worked?! 
  

write.csv(meso_lookup_id, here("data/model_features/mesopelagiczones/mesopelagiczones.csv"), row.names = FALSE)

```


Prep el nino data

```{r}
elnino <-  read.table(url("https://psl.noaa.gov/data/correlation/oni.data"),skip=1,nrows=72) %>%
    as_tibble() %>%
    rename(year = V1) %>%
    pivot_longer(-year) %>%
    mutate(month = stringr::str_remove_all(name,"V") %>%
             as.numeric() - 1,
           date = lubridate::ymd(glue::glue("{year}-{month}-1")),
           year = lubridate::year(date)) %>%
    dplyr::select(year,enso_index = value) %>%
    filter(year >= 2015,
           year <= 2021)%>%
    group_by(year) %>%
    summarize(across(everything(),list(mean = ~mean(.,na.rm=TRUE),
                                       sd = ~sd(.,na.rm=TRUE)))) %>%
    ungroup()

write.csv(elnino, here("data/model_features/enso_index.csv"), row.names = FALSE)
```


Pacific Decadal Oscillation index 

```{r}

# Pull and wrangle PDO data from NOAA
# ttps://psl.noaa.gov/data/climateindices/list/
# Calculate annual mean and SD for our time period of interest
wrangle_pdo_data <- 
  read.table(url("https://psl.noaa.gov/data/correlation/pdo.data"),skip=1,nrows=74) %>%
    as_tibble() %>%
    rename(year = V1) %>%
    pivot_longer(-year) %>%
    mutate(month = stringr::str_remove_all(name,"V") %>%
             as.numeric() - 1,
           date = lubridate::ymd(glue::glue("{year}-{month}-1")),
           year = lubridate::year(date)) %>%
    dplyr::select(year,pdo_index = value) %>%
    filter(year >= 2015,
           year <= 2021)%>%
    mutate(pdo_index = ifelse(pdo_index == -9.9,NA_real_,pdo_index))%>%
    group_by(year) %>%
    summarize(across(everything(),list(mean = ~mean(.,na.rm=TRUE),
                                       sd = ~sd(.,na.rm=TRUE)))) %>%
    ungroup()

write.csv(wrangle_pdo_data, here("data/model_features/pdo_index.csv"), row.names = FALSE)

```


Distance to seamount data 

```{r}

library(nngeo)

pixel_size <- 1

mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

# Read in data_grid, generated in data_wrangling.Rmd
# We will do spatial joining in Mollweide, for proper calculations
# Note that data grid still retains lat and lon columns, for joining with non-spatial tibbles
# For Mollweide, always wrap around dateline, then transform, then calculate areas at end
data_grid <- data.table::fread(here("data/model_features/deg_1_x_1/global_grid.csv"))%>%
  st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 

seamounts <- st_read(file.path(rdsi_raw_dir, "seamounts-yesson-2019/"), layer = "YessonEtAl2019-Seamounts-V2")

analysis_projection = mollweide_projection

global_grid = data_grid

# Wrangle seamounts data
# Calculate nearest distance from the centroid of each pixel to each seamount

  seamounts <- seamounts %>%
    dplyr::select(seamount_id = PeakID,
                  geometry)%>% 
    st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
    st_transform(analysis_projection)
  
  wrangle_seamounts <- nngeo::st_nn(global_grid %>%
                 st_centroid(),
               seamounts, 
               # Only select single nearest eez
               k = 1, 
               returnDist = T,
               parallel = 1) %>%# floor(parallel::detectCores()/4))  %>% 
    as_tibble() %>% 
    mutate(nearest_seamount_id =  seamounts$seamount_id[as.numeric(nn)], 
           nearest_seamount_distance_m = as.numeric(dist)) %>%
    dplyr::select(-nn,-dist) %>%
    bind_cols(global_grid %>%
                st_set_geometry(NULL) %>%
                dplyr::select(pixel_id))

  write.csv(wrangle_seamounts, here("data/model_features/deg_1_x_1/seamounts.csv"), row.names = FALSE)
  
```


Global fishing index data 

```{r}
library(readxl)

gfi_raw <- readxl::read_xlsx("/home/ubuntu/data_storage/raw_data/Global Fishing Index 2021 - Data download V1.1/Global Fishing Index 2021 Data for Download V1.1.xlsx", sheet = 3, skip = 1)  %>% 
  dplyr::select(flag_fin  = "ISO Code", gov_score = "Governance capacity") %>%
  mutate(gov_score = as.factor(gov_score)) # make it into a categorical variable

write.csv(gfi_raw, here("data/model_features/global_fishing_index_governance.csv"), row.names = FALSE)
```

