---
title: "Create fishing access dataset"
output: html_document
date: "2025-08-26"
---

# Summary

Here we create a dataset that described for each flag country, the EEZs they are able to fish in for each year. We derive this data from Rousseau et al, who derived it from Watson et al, who used fishing access rights datasets.

The data will be formatted as year \| flag country \| eez (including high seas?) \| fishing (1 or 0)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(countrycode)
library(sf)
library(qs)
library(data.table)
library(terra)

source(here("R/dir.R"))
```

```{r}
eez_lookup <- read.csv(here("data/model_features/deg_1_x_1/eez/eez_lookup_fix.csv"))

eez <- read.csv(here("data/model_features/deg_1_x_1/eez/eez_fix.csv")) %>%
  left_join(eez_lookup) 

saup_codes <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/SAUPtoCountry.csv")
```

Read in gridded fishing effort by flag country from Rousseau et al.: https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/

This is 0.5 degrees, so we need to resample the lat lons to match ours and then join to our 0.5 degree eez dataframe to get the fishing location

```{r}
data_grid_5 <- read.csv(here("data/model_features/global_grid.csv")) %>%
  st_drop_geometry() %>%
  dplyr::select(-geometry_wkt)

eez_lookup_5 <- read.csv(here("data/model_features/eez/eez_lookup_fix.csv"))

eez_5 <- read.csv(here("data/model_features/eez/eez_fix.csv")) %>%
  left_join(eez_lookup_5)  %>%
  left_join(data_grid_5)

options(timeout = 1000)

url <- "https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/GriddedEffortby_FishingCountry.csv"
grid_effort_flag_raw <- fread(url, showProgress = TRUE)  # very fast parser

# 1) Templates: one with centers at .25/.75 (source), one at .0/.5 (target)
r_src <- rast(
  ext(-180, 180, -90, 90),     # boundaries at integers -> centers .25/.75
  resolution = 0.5, crs = "EPSG:4326"
)

r_tgt <- rast(
  ext(-180.25, 180.25, -90.25, 90.25),  # boundaries shifted -> centers .0/.5
  resolution = 0.5, crs = "EPSG:4326"
)

r_tgt <- rast(data_grid_5 %>% dplyr::select(lon, lat, pixel_id), type = "xyz")

# 2) Build a lookup FROM the .25/.75 grid TO the .0/.5 grid
#    (use your actual source table of points to limit to cells you actually need)
src_pts <- vect(grid_effort_flag_raw, geom = c("Lon","Lat"), crs = "EPSG:4326")

# for each source point, which target cell contains it?
tgt_cells <- cellFromXY(r_tgt, crds(src_pts))

# target cell centers (snapped lon/lat)
tgt_xy <- xyFromCell(r_tgt, tgt_cells)

lookup_src_to_tgt <- tibble::tibble(
  Lon_src  = grid_effort_flag_raw$Lon,
  Lat_src  = grid_effort_flag_raw$Lat,
  lon_tgt  = tgt_xy[,1],
  lat_tgt  = tgt_xy[,2]
) %>%
  # keep a stable 1-decimal representation (avoids float fuzz)
  mutate(
    lon_tgt = as.numeric(sprintf("%.1f", lon_tgt)),
    lat_tgt = as.numeric(sprintf("%.1f", lat_tgt))
  ) %>%
  distinct(Lon_src, Lat_src, .keep_all = TRUE)

# Example join: snap the effort data to the EEZ scheme
grid_effort_flag_snap <- grid_effort_flag_raw %>%
  left_join(lookup_src_to_tgt,
            by = c("Lon" = "Lon_src", "Lat" = "Lat_src")) %>%
  rename(lon = lon_tgt, lat = lat_tgt)

# Now you can left_join onto eez_5 by c("lon","lat")
out <- grid_effort_flag_snap %>%
  left_join(eez_5, by = c("lon","lat"))

# test <- filter(out, is.na(lat)|is.na(lon)) # 0 good! 
# test <- filter(out, is.na(eez_sovereign)) # ok sooo missing ~1% of rows 
# 
# test <- out %>% 
#   filter(Country == "IND", 
#          is.na(eez_sovereign), 
#          Year == 2003) %>%
#   dplyr::select(lon, lat, NV) %>%
#   rast(., type = "xyz")
# 
# plot(test, col = "red") # all coastal..? So maybe I should assign the NAs its closest existent neighbor pixel? 

missing_pixels <- out %>%
  filter(is.na(pixel_id))

setDT(missing_pixels)
setDT(data_grid_5)

# Build grid points once
grid_pts <- vect(data_grid_5, geom = c("lon","lat"), crs = "EPSG:4326")

# Unique lon/lat among the NAs
uniq_xy <- unique(missing_pixels[is.na(pixel_id), .(lon, lat)])
uniq_pts <- vect(uniq_xy, geom = c("lon","lat"), crs = "EPSG:4326")

library(FNN)

X <- as.matrix(data_grid_5[, c("lon","lat")])   # reference points
Q <- as.matrix(uniq_xy[, c("lon","lat")])       # query (unique missing)

kn <- get.knnx(X, Q, k = 1)
to_idx <- kn$nn.index[, 1]

lookup_nn <- data.table(
  lon_old      = uniq_xy$lon,
  lat_old      = uniq_xy$lat,
  pixel_id = data_grid_5$pixel_id[to_idx]
) %>%
  left_join(data_grid_5, by = "pixel_id")


missing_data_fix <- missing_pixels %>%
  as.data.frame() %>%
  dplyr::select(-pixel_id, -eez_id, -eez_sovereign) %>%
  left_join(lookup_nn, by = c("lon" = "lon_old", "lat" = "lat_old")) %>%
  dplyr::select(-lon, -lat) %>%
  dplyr::rename(lon_old = Lon, lat_old = Lat, lon = lon.y, lat = lat.y) %>%
  left_join(eez_5)

all_data_matched_effort <- out %>%
  filter(!is.na(pixel_id)) %>%
  rename(lon_old = Lon, lat_old = Lat) %>%
  rbind(., missing_data_fix)


all_data_distinct_access <- all_data_matched_effort %>% 
  filter(NomActiveHours > 0) %>%
  distinct(year = Year, flag_fin = Country, eez_sovereign) %>%
  mutate(access = 1)

qs::qsave(all_data_distinct_access, here("data/int/prediction_historical_data/fishing_access.qs"))


```


Create access mask for high seas areas and use FAO areas as access areas for those

```{r}
fao_df <- read.csv(here("data/model_features/fao/fao_fixed.csv")) %>%
  left_join(read.csv(here("data/model_features/fao/fao_major_ids.csv")))

effort_access_df_highseas <- all_data_matched_effort %>%
  filter(NomActiveHours > 0, 
         eez_sovereign == "High seas") %>%
  left_join(fao_df) %>%
  mutate(access_fao = 1) %>%
  distinct(year = Year, flag_fin = Country, eez_country_name = eez_sovereign, fao_id, fao_area_name = name_en, access_fao)
  
qs::qsave(effort_access_df_highseas, here("data/int/prediction_historical_data/high_seas_fao_fishing_access.qs"))

```

Instead of using the pre-existing Watson data already processed by Cami (and using a different EEZ mask), we will pull using our own EEZ mask:

Read in the data: 

```{r}
library(janitor)

# big file, takes a long time to load. 
watson_industrial_catch <- read.csv("/home/ubuntu/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/NonHistoricalIndCami_toCombine/NonHistoricalIndCami.csv") %>%
  clean_names() %>%
  mutate(catch = reported+iuu) %>%
  group_by(year, c_number, lon, lat) %>%
  summarise(catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(catch > 0, 
         year >= 1950)

library(readxl)

c_codes <- read_xlsx("/home/ubuntu/gem/private/users/yannickr/Reg_catchData/20220606_RegCatchData/CodesRevisedJune2022.xlsx", sheet = 6) %>%
  clean_names() %>%
  dplyr::select(c_number = cnumber_1, country_name = fao_name) %>% 
  mutate(flag_fin = countrycode::countrycode(country_name, origin = "country.name", destination = "iso3c")) %>% 
    mutate(flag_fin = case_when(
    country_name == "Dominican Rp" ~ "DOM",
    country_name == "NethAntilles" ~ "NLD",
    country_name %in% c("US Virgin Is", "Amer Samoa") ~ "USA",
    country_name %in% c("Channel Is", "Br Virgin Is", "Br Ind Oc Tr") ~ "GBR",
    country_name == "Untd Arab Em" ~ "ARE",
    country_name == "Micronesia" ~ "FSM",
    country_name == "Falkland Is" ~ "ARG",
    country_name == "Gibraltar" ~ "GBR",
    country_name %in% c("Macau") ~ "CHN",
    country_name == "Fr Guiana" ~ "GUF",
    country_name == "Fr Polynesia" ~ "PYF",
    country_name == "St Pier Mq" ~ "FRA",
    country_name == "Yugoslavia" ~ "YUG", 
    country_name == "Other nei" ~ "NEI", 
    TRUE ~ flag_fin)) %>%
  distinct(flag_fin, country_name, c_number)

catch_df_access <- watson_industrial_catch %>% 
  # distinct(year, lon, lat, c_number) %>%
  left_join(c_codes) %>%
 # distinct(year, lon, lat, flag_fin)
  group_by(year, lon, lat, flag_fin) %>%
  summarise(catch = sum(catch, na.rm = TRUE)) %>%
  ungroup()



test <- watson_industrial_catch %>% 
  distinct(year, lon, lat, c_number) %>%
  left_join(c_codes) %>%
 distinct(year, lon, lat, flag_fin)

test <- watson_industrial_catch %>% 
  filter(year == 2017) %>%
  left_join(c_codes) %>%
  filter(country_name == "Benin")

test_r <- test %>%
  group_by(lon, lat) %>%
  summarise(catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  rast(., type = "xyz")
plot(test_r, col = "red") # ok weird, this is mostly in west africa... so is our access mask wrong? I think it is maybe that some of the catch is in one cell in China for example. A simple threshold would probably work (e.g., <1% of a flag country's catch, then don't consider it?)

```

Now apply the same methodology as above for the catch data pull:

```{r}
data_grid_5 <- read.csv(here("data/model_features/global_grid.csv")) %>%
  st_drop_geometry() %>%
  dplyr::select(-geometry_wkt)

eez_lookup_5 <- read.csv(here("data/model_features/eez/eez_lookup_fix.csv"))

eez_5 <- read.csv(here("data/model_features/eez/eez_fix.csv")) %>%
  left_join(eez_lookup_5)  %>%
  left_join(data_grid_5)


# 1) Templates: one with centers at .25/.75 (source), one at .0/.5 (target)
r_src <- rast(
  ext(-180, 180, -90, 90),     # boundaries at integers -> centers .25/.75
  resolution = 0.5, crs = "EPSG:4326"
)

r_tgt <- rast(data_grid_5 %>% dplyr::select(lon, lat, pixel_id), type = "xyz", crs = "EPSG:4326")

# 2) Build a lookup FROM the .25/.75 grid TO the .0/.5 grid
#    (use your actual source table of points to limit to cells you actually need)
src_pts <- vect(catch_df_access, geom = c("lon","lat"), crs = "EPSG:4326")

# for each source point, which target cell contains it?
tgt_cells <- cellFromXY(r_tgt, crds(src_pts))

# target cell centers (snapped lon/lat)
tgt_xy <- xyFromCell(r_tgt, tgt_cells)

lookup_src_to_tgt <- tibble::tibble(
  lon_src  = catch_df_access$lon,
  lat_src  = catch_df_access$lat,
  lon_tgt  = tgt_xy[,1],
  lat_tgt  = tgt_xy[,2]
) %>%
  # keep a stable 1-decimal representation (avoids float fuzz)
  mutate(
    lon_tgt = as.numeric(sprintf("%.1f", lon_tgt)),
    lat_tgt = as.numeric(sprintf("%.1f", lat_tgt))
  ) %>%
  distinct(lon_src, lat_src, .keep_all = TRUE)

# Example join: snap the effort data to the EEZ scheme
grid_catch_flag_snap <- catch_df_access %>%
  rename(lon_old = lon, lat_old = lat) %>%
  left_join(lookup_src_to_tgt,
            by = c("lon_old" = "lon_src", "lat_old" = "lat_src")) %>%
  rename(lon = lon_tgt, lat = lat_tgt)

# Now you can left_join onto eez_5 by c("lon","lat")
out <- grid_catch_flag_snap %>%
  left_join(eez_5, by = c("lon","lat"))

# test <- filter(out, is.na(lat)|is.na(lon)) # 0 good! 
# test <- filter(out, is.na(eez_sovereign)) # ok sooo missing ~<1% of rows 
# 
# test <- out %>% 
#   filter(flag_fin == "IND", 
#          is.na(eez_sovereign), 
#          year == 2003) %>%
#   dplyr::select(lon, lat, year) %>%
#   rast(., type = "xyz")
# 
# plot(test, col = "red") # all coastal..? So maybe I should assign the NAs its closest existent neighbor pixel? 

missing_pixels <- out %>%
  filter(is.na(pixel_id))

setDT(missing_pixels)
setDT(data_grid_5)

# Build grid points once
grid_pts <- vect(data_grid_5, geom = c("lon","lat"), crs = "EPSG:4326")

# Unique lon/lat among the NAs
uniq_xy <- unique(missing_pixels[is.na(pixel_id), .(lon, lat)])
uniq_pts <- vect(uniq_xy, geom = c("lon","lat"), crs = "EPSG:4326")

library(FNN)

X <- as.matrix(data_grid_5[, c("lon","lat")])   # reference points
Q <- as.matrix(uniq_xy[, c("lon","lat")])       # query (unique missing)

kn <- get.knnx(X, Q, k = 1)
to_idx <- kn$nn.index[, 1]

lookup_nn <- data.table(
  lon_old      = uniq_xy$lon,
  lat_old      = uniq_xy$lat,
  pixel_id = data_grid_5$pixel_id[to_idx]
) %>%
  left_join(data_grid_5, by = "pixel_id")


missing_data_fix <- missing_pixels %>%
  as.data.frame() %>%
  dplyr::select(-pixel_id, -eez_id, -eez_sovereign) %>%
  left_join(lookup_nn, by = c("lon" = "lon_old", "lat" = "lat_old")) %>%
  dplyr::select(-lon, -lat) %>%
  dplyr::rename(lon = lon.y, lat = lat.y) %>%
  left_join(eez_5)

all_data_matched_catch <- out %>%
  filter(!is.na(pixel_id)) %>%
  rbind(., missing_data_fix)


# all_data_distinct_access_catch <- all_data_matched_catch %>%
#   distinct(year, flag_fin, eez_sovereign, eez_id) %>%
#   mutate(access = 1)

all_data_distinct_access_catch <- all_data_matched_catch %>% 
  group_by(year, flag_fin, eez_sovereign, eez_id) %>%
  summarise(catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year, flag_fin) %>%
  mutate(flag_catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_catch = catch/flag_catch) %>%
  mutate(access = ifelse(prop_flag_catch >= 0.01 | catch >= 100, 1, 0)) %>%
  filter(access == 1) # doing it this way removes ~2/3 of the rows 

test_ben <- all_data_distinct_access_catch %>%
  filter(year == 2017,
         flag_fin == "USA") %>%
  filter(prop_flag_catch >= 0.01|catch >= 100)
  
```

Fix Ukraine and Slovenia access data: It is not in the Watson data before 1988 (Ukraine) and 1992 (Slovenia), so we will use the Rousseau effort data for those years
 - filter for hours of effort > 100 hours
 - create a master list of countries where Ukraine and Slovenia fish in from the Watson data from 1990-2000
 - Only include countries in the rousseau data if they are also in the watson data from 1990-2000

We also need to add RAM and RAA to the Watson data, and we will use the data from Rousseau for this, using the same rules. 

```{r}
# Ukraine first
ukraine_watson <- all_data_distinct_access_catch %>%
  filter(year %in% c(1990:2000),
         flag_fin == "UKR") %>%
  distinct(flag_fin, eez_sovereign, access, eez_id)

rousseau_access <- qread(here("data/int/prediction_historical_data/fishing_access.qs"))

ukr_rousseau_access <- all_data_matched_effort %>% 
  filter(NomActiveHours > 0) %>%
  rename(year = Year) %>% 
  group_by(year, Country, eez_sovereign) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year, Country) %>%
  mutate(effort_flag = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_effort = NomActiveHours/effort_flag) %>%
  dplyr::select(year, flag_fin = Country, eez_sovereign, NomActiveHours, prop_flag_effort) %>%
  filter(flag_fin == "UKR") %>% # maybe filter for >100 hours when we have to use this? 
  filter(NomActiveHours >= 100|prop_flag_effort >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign) %>%
  mutate(access = 1) %>%
  filter(year < 1988) 


ukr_access_1950_1987 <- ukr_rousseau_access %>%
  filter(eez_sovereign %in% unique(ukraine_watson$eez_sovereign)) %>%
  left_join(eez_lookup)


# Slovenia next 
slovenia_watson <- all_data_distinct_access_catch %>%
  filter(year %in% c(1990:2000),
         flag_fin == "SVN") %>%
  distinct(flag_fin, eez_sovereign, access, eez_id)

svn_rousseau_access <- all_data_matched_effort %>% 
  filter(NomActiveHours > 0) %>%
  rename(year = Year) %>% 
  group_by(year, Country, eez_sovereign) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
    group_by(year, Country) %>%
  mutate(effort_flag = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_effort = NomActiveHours/effort_flag) %>%
  dplyr::select(year, flag_fin = Country, eez_sovereign, NomActiveHours, prop_flag_effort) %>%
  filter(flag_fin == "SVN") %>% # maybe filter for >100 hours when we have to use this? 
    filter(NomActiveHours >= 100|prop_flag_effort >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign) %>%
  mutate(access = 1) %>%
  filter(year < 1992) 


svn_access_1950_1991 <- svn_rousseau_access %>%
  filter(eez_sovereign %in% unique(slovenia_watson$eez_sovereign)) %>% # now make sure that we only allow fishing in areas that Watson says they can actually fish, since we trust that more. 
  left_join(eez_lookup)

prt_watson <- all_data_distinct_access_catch %>%
    filter(
         flag_fin == "PRT") %>%
  distinct(flag_fin, eez_sovereign, access, eez_id)

RAA_RAM <- all_data_matched_effort %>%
    filter(NomActiveHours > 0) %>%
  rename(year = Year) %>% 
  group_by(year, Country, eez_sovereign) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
      group_by(year, Country) %>%
  mutate(effort_flag = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_effort = NomActiveHours/effort_flag) %>%
  dplyr::select(year, flag_fin = Country, eez_sovereign, NomActiveHours, prop_flag_effort) %>%
    filter(flag_fin %in% c("RAA", "RAM")) %>% # maybe filter for >100 hours when we have to use this? 
      filter(NomActiveHours >= 100|prop_flag_effort >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign) %>%
  mutate(access = 1) %>%
  distinct()

ram_raa_df <- RAA_RAM %>%
    filter(eez_sovereign %in% unique(prt_watson$eez_sovereign)) %>% # now make sure that we only allow fishing in areas that Watson says they can actually fish, since we trust that more. 
  left_join(eez_lookup)

catch_access_fin <- all_data_distinct_access_catch %>%
  dplyr::distinct(year, flag_fin, eez_sovereign, access, eez_id) %>%
  rbind(ukr_access_1950_1987, svn_access_1950_1991, ram_raa_df)

# colnames(all_data_distinct_access_catch)
# colnames(ukr_access_1950_1987)
  
# fix faroe islands data 
fro_access_1951 <- catch_access_fin %>%
  filter(flag_fin == "FRO", 
         year == 1952) %>%
  mutate(year = 1951)

fro_access_1950 <- catch_access_fin %>%
  filter(flag_fin == "FRO", 
         year == 1952) %>%
  mutate(year = 1950)


catch_access_fin <- catch_access_fin %>%
  rbind(fro_access_1950, fro_access_1951)

test <- catch_access_fin %>%
  filter(flag_fin == "BEN", 
         year == 2017)

```


Assume any access had in from 2013-2017 (last 5 years of data) moves forward to 2024 for each country  

```{r}
catch_access_future <- catch_access_fin %>%
  filter(year %in% 2013:2017) %>%
  distinct(flag_fin, eez_sovereign, access, eez_id) %>%
  crossing(., year = c(2018:2024))
```


Read in GFW data and assume that if a flag is fishing in a EEZ, they have access

```{r}
# years <- 2015:2024
# gfw_data <- list()
# 
# library(glue)
# 
# for(yr in years) {
#   # yr = 2015
#   # Load effort proportions
#   effort_props <- qread(file.path(rdsi_dir, glue("prep/gfw_props/deg_one/all_effort_gear_length_props_{yr}.qs"))) %>%
#     mutate(year = yr) %>%
#     filter(fishing_hours > 0)
# 
#   
#   # Combine all data
#   year_data <- effort_props %>%
#     dplyr::distinct(
#       year, 
#       flag_fin, 
#       eez_sovereign = iso_sov1
#     )
#   
# #  test <- year_data %>% filter(is.na(eez_sovereign))
#   
#   gfw_data[[as.character(yr)]] <- year_data
# }
# 
# # Combine all years
# final_data <- bind_rows(gfw_data) %>%
#   mutate(eez_sovereign = ifelse(eez_sovereign == "HSX", "High seas", eez_sovereign)) %>%
#   mutate(access = 1) %>%
#   filter(eez_sovereign != "LND") %>%
#   filter(!is.na(eez_sovereign)) %>%
#   left_join(eez_lookup)

all_catch_access <- rbind(catch_access_fin, catch_access_future) %>%
  distinct()

# qs::qsave(all_catch_access, here("data/int/prediction_historical_data/catch_fishing_access.qs"))

unique(all_catch_access$eez_sovereign)
unique(all_catch_access$flag_fin)

## ok now we need to make sure EVERY FLAG FOR EVERY YEAR HAS ACCESS TO THEIR OWN EEZ

# all_catch_access <- qs::qread(here("data/int/prediction_historical_data/catch_fishing_access.qs"))


own_eez_access <- data.frame(year = NA, flag_fin = NA, eez_sovereign = NA, access = NA)

flags <- unique(all_catch_access$flag_fin)
years <- c(1950:2024)

for(flag in flags){
  for(yr in years){
  
    own_eez_access <- own_eez_access %>%
      add_row(year = yr, flag_fin = flag, eez_sovereign = flag, access = 1)
    
    
  }
}

own_eez_access_fin <- own_eez_access %>%
  filter(!is.na(year)) %>%
  left_join(eez_lookup)

all_access_fin <- rbind(all_catch_access, own_eez_access_fin) %>%
  distinct()

qs::qsave(all_access_fin, here("data/int/prediction_historical_data/catch_fishing_access.qs"))

```


Now do FAO high seas access

```{r}
fao_lookup <- read.csv(here("data/model_features/fao/fao_major_ids.csv"))

fao_df <- read.csv(here("data/model_features/fao/fao_fixed.csv"))

catch_access_df_highseas <- all_data_matched_catch %>%
  filter(
         year >= 1950, 
         eez_sovereign == "High seas") %>%
  left_join(fao_df) %>%
  left_join(fao_lookup, by = c("fao_id")) %>%
  dplyr::select(year, flag_fin, fao_id, fao_area_name = name_en, eez_sovereign, catch) %>%
  group_by(year, flag_fin, fao_id, fao_area_name, eez_sovereign) %>%
  summarise(catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  group_by(year, flag_fin) %>%
  mutate(flag_catch = sum(catch, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag = catch/flag_catch) %>%
  mutate(access_fao = ifelse(prop_flag >= 0.01|catch >= 100, 1, 0))

test_chn <- catch_access_df_highseas %>%
  filter(flag_fin == "BEN",
         year == 2017)

ukraine_watson <- catch_access_df_highseas %>%
  filter(year %in% c(1990:2000),
         flag_fin == "UKR") %>%
  distinct(flag_fin, eez_sovereign, fao_id, fao_area_name, access_fao)

# fix ukraine 
ukraine_effort_highseas <- all_data_matched_effort %>%
  filter(NomActive > 0, 
        Year >= 1950,
        eez_sovereign == "High seas") %>%
  rename(year = Year) %>%
  left_join(fao_df) %>%
   dplyr::select(year, flag_fin = Country, eez_sovereign, fao_id, NomActiveHours) %>%
  group_by(year, flag_fin, eez_sovereign, fao_id) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  dplyr::select(year, flag_fin, eez_sovereign, fao_id, NomActiveHours) %>%
  group_by(year, flag_fin) %>%
  mutate(flag_eff = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_eff = NomActiveHours/flag_eff) %>%
  filter(flag_fin == "UKR") %>% # maybe filter for >100 hours when we have to use this? 
  filter(NomActiveHours >= 100|prop_flag_eff >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign, fao_id) %>%
  mutate(access_fao = 1) %>%
  filter(year < 1988) %>%
  filter(fao_id %in% c(unique(ukraine_watson$fao_id))) %>%
  left_join(fao_lookup, by = c("fao_id")) %>%
  rename(fao_area_name = name_en) %>%
  dplyr::select(-ocean)
  
# fix slovenia 
slovenia_watson <- catch_access_df_highseas %>%
  filter(year %in% c(1990:2000),
         flag_fin == "SVN") %>%
  distinct(flag_fin, eez_sovereign, fao_id, fao_area_name, access_fao)

slovenia_effort_highseas <- all_data_matched_effort %>%
  filter(NomActiveHours > 0, 
        Year >= 1950,
        eez_sovereign == "High seas") %>%
  rename(year = Year) %>%
  left_join(fao_df) %>%
  dplyr::select(year, flag_fin = Country, eez_sovereign, fao_id, NomActiveHours) %>%
  group_by(year, flag_fin, eez_sovereign, fao_id) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  dplyr::select(year, flag_fin, eez_sovereign, fao_id, NomActiveHours) %>%
    group_by(year, flag_fin) %>%
  mutate(flag_eff = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_eff = NomActiveHours/flag_eff) %>%
  filter(flag_fin == "SVN") %>% # maybe filter for >100 hours when we have to use this? 
    filter(NomActiveHours >= 100|prop_flag_eff >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign, fao_id) %>%
  mutate(access_fao = 1) %>%
  filter(year < 1992) %>%
  filter(fao_id %in% c(unique(slovenia_watson$fao_id))) %>%
  left_join(fao_lookup, by = c("fao_id")) %>%
  rename(fao_area_name = name_en) %>%
  dplyr::select(-ocean)


# now do RAA and RAM 
prt_watson_hs <- catch_access_df_highseas %>%
    filter(
         flag_fin == "PRT") %>%
  distinct(flag_fin, eez_sovereign, fao_id, fao_area_name, access_fao)

RAA_RAM_hs <- all_data_matched_effort %>%
  filter(NomActiveHours > 0, 
        Year >= 1950,
        eez_sovereign == "High seas") %>%
  rename(year = Year) %>%
  left_join(fao_df) %>%
  dplyr::select(year, flag_fin = Country, eez_sovereign, fao_id, NomActiveHours) %>%
  group_by(year, flag_fin, eez_sovereign, fao_id) %>%
  summarise(NomActiveHours = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  dplyr::select(year, flag_fin, eez_sovereign, fao_id, NomActiveHours) %>%
      group_by(year, flag_fin) %>%
  mutate(flag_eff = sum(NomActiveHours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(prop_flag_eff = NomActiveHours/flag_eff) %>%
  filter(flag_fin %in% c("RAA", "RAM")) %>% # maybe filter for >100 hours when we have to use this? 
      filter(NomActiveHours >= 100|prop_flag_eff >= 0.01) %>%
  distinct(year, flag_fin, eez_sovereign, fao_id) %>%
  mutate(access_fao = 1) %>%
  filter(year < 1992) %>%
  filter(fao_id %in% c(unique(prt_watson_hs$fao_id))) %>%
  left_join(fao_lookup, by = c("fao_id")) %>%
  rename(fao_area_name = name_en) %>%
  dplyr::select(-ocean)


catch_access_df_highseas_fin <- catch_access_df_highseas %>%
  dplyr::select(year, flag_fin, eez_sovereign, fao_id, access_fao, fao_area_name) %>%
  rbind(ukraine_effort_highseas, slovenia_effort_highseas, RAA_RAM_hs) %>%
  filter(access_fao == 1)

# fix faroe islands data 
fro_access_1951 <- catch_access_df_highseas_fin %>%
  filter(flag_fin == "FRO", 
         year == 1952) %>%
  mutate(year = 1951)
fro_access_1950 <- catch_access_df_highseas_fin %>%
  filter(flag_fin == "FRO", 
         year == 1952) %>%
  mutate(year = 1950)


catch_access_df_highseas_fin <- catch_access_df_highseas_fin %>%
  rbind(fro_access_1950, fro_access_1951) %>%
  filter(flag_fin != "") %>%
  filter(!is.na(flag_fin))


# now do future by just taking hte latest 5 years
catch_access_hs_future <- catch_access_df_highseas_fin %>%
  filter(year %in% 2013:2017) %>%
  distinct(flag_fin, fao_id, fao_area_name, eez_sovereign, access_fao) %>%
  crossing(., year = c(2018:2024))


# ## now do GFW data 
# years <- 2015:2024
# gfw_data <- list()
# 
# data_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv")) %>%
#   dplyr::select(pixel_id, lat, lon)
# 
# # read in FAO area spatial csv 
# fao_lookup <- read.csv(here("data/model_features/deg_1_x_1/fao/fao_major_ids.csv"))
# fao_spatial <- read.csv(here("data/model_features/deg_1_x_1/fao/fao_fixed.csv")) %>%
#   left_join(fao_lookup) %>%
#   left_join(data_grid) %>%
#     dplyr::select(fao_area = fao_id, fao_area_name = name_en, x = lon, y = lat) 
#  
# 
# for(yr in years) {
#   # yr = 2015
#   # Load effort proportions
#   effort_props <- qread(file.path(rdsi_dir, glue("prep/gfw_props/deg_one/all_effort_gear_length_props_{yr}.qs"))) %>%
#     mutate(year = yr) %>%
#     filter(fishing_hours > 0) %>%
#     left_join(fao_spatial) %>%
#     filter(iso_sov1 == "HSX")
# 
#   
#   # Combine all data
#   year_data <- effort_props %>%
#     dplyr::distinct(
#       year, 
#       flag_fin, 
#       eez_country_name = sovereign1, 
#       fao_area, 
#       fao_area_name
#     ) %>%
#     filter(!is.na(fao_area))
#   
#   gfw_data[[as.character(yr)]] <- year_data
# }
# 
# # Combine all years
# final_data <- bind_rows(gfw_data) %>%
#   mutate(access_fao = 1) %>%
#   rename(eez_sovereign = eez_country_name,
#          fao_id = fao_area)

all_catch_access_hs <- rbind(catch_access_df_highseas_fin, catch_access_hs_future) %>%
  distinct()

qs::qsave(catch_access_df_highseas_fin, here("data/int/prediction_historical_data/catch_fishing_access_high_seas.qs"))

```

