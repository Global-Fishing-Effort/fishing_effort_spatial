---
title: "Predict props to cells per flag, year, gear, length"
output: html_document
date: "2024-12-11"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(progress)
library(pryr)  # for memory tracking
library(glue)
library(qs)
library(here)
library(randomForest)
library(janitor)
library(arrow)
library(countrycode)
library(sf)
library(ranger)
library(data.table)

source(here("R/dir.R"))
```

## Functions to prepare enviro and effort data  

```{r}

elnino <- read.csv(here("data/model_features/enso_index.csv"))

pdo <- read.csv(here("data/model_features/pdo_index.csv"))

world_bank <- read.csv(here("data/model_features/world_bank_regions.csv"))

gfi_df <- read.csv(here("data/model_features/global_fishing_index_governance.csv"))
  
# Load prepared data
model_data <- readRDS(here("data/model_features/prepared_data_1deg.rds")) %>%
  mutate(year = as.numeric(year)) # i think we need to adjust the prepared data to include cells which have no fishing effort in them. We can do this in the loop below? 

## read in environmental variables

  global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv"))
  
  ocean_data <- read.csv(here("data/model_features/deg_1_x_1/errdap_chl.csv")) %>%
  left_join(read.csv(here("data/model_features/deg_1_x_1/errdap_sst.csv")), by = c("pixel_id", "year")) %>% 
  left_join(read.csv(here("data/model_features/deg_1_x_1/remss_wind.csv")), by = c("pixel_id", "year")) %>%
  filter(year %in% c(2015:2024))
  
  ocean_data_historical <- qs::qread(here("data/int/prediction_historical_data/one_degree/chl_yearly_1950_2014.qs")) %>%
    dplyr::select(-pixel_area_m2) %>%
  left_join(qs::qread(here("data/int/prediction_historical_data/one_degree/sst_yearly_1950_2014.qs")) %>%  dplyr::select(-pixel_area_m2), by = c("pixel_id", "year")) %>% 
  left_join(qs::qread(here("data/int/prediction_historical_data/one_degree/wind_yearly_1950_2014.qs")) %>% mutate(year = as.numeric(year)) %>% dplyr::select(-pixel_area_m2), by = c("pixel_id", "year"))

  ocean_data_all <- ocean_data %>%
    rbind(ocean_data_historical)

  spatial_data <- global_grid %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/gfw_static_spatial_measures.csv")) %>% dplyr::select(-lat, -lon), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/mesopelagiczones/mesopelagiczones_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/eez/eez_fix.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/fao/fao_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/oceans_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/seamounts.csv")), by = "pixel_id") %>% 
   crossing(., year = c(1950:2024)) 
  
    gfw_reception_data <- read.csv(here("data/model_features/deg_1_x_1/gfw_reception_quality.csv"))
    
    sea_ice_df <- qs::qread(here("data/model_features/deg_1_x_1/sea_ice_features_lit.qs"))
  
  env_data <- spatial_data %>%
    left_join(sea_ice_df) %>%
    left_join(ocean_data_all) %>% # cool.
    left_join(elnino) %>%
    left_join(pdo) %>% 
    left_join(gfw_reception_data) %>%
    left_join(world_bank, by = c("eez_id")) %>%
    mutate(eez_region_world_bank_7 = ifelse(eez_id %in% c("High seas", "Land"), "High seas", eez_region_world_bank_7)) %>% 
    left_join(gfi_df, by = c("eez_sovereign" = "flag_fin")) %>% # add in global fishing index data here
    mutate(gov_score = ifelse(eez_id >= 99999 & is.na(gov_score), "high_seas", gov_score)) %>%
        mutate(gov_score = ifelse(eez_id < 99999 & is.na(gov_score), "no_data", gov_score)) %>%
    dplyr::select(-eez_sovereign, -nearest_seamount_id) %>% 
    distinct()  %>%
    dplyr::select(-geometry_wkt)

mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

data_grid_area <- global_grid %>%
    st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 

```

```{r}

  hist_fish_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    dplyr::select(flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name"))

  
flags <- unique(hist_fish_data$flag_fin) # get the flags we need to run models for # 151 of them

```


Read in EEZ id and FAO id lookup tables so we can save with the actual iso3c and FAO id numbers

```{r}

eez_lookup <- read.csv(here("data/model_features/deg_1_x_1/eez/eez_lookup_fix.csv")) %>%
  clean_names() %>%
  mutate(eez_country_name = countrycode(eez_sovereign, origin = "iso3c", destination = "country.name")) %>%
    mutate(eez_country_name = case_when(
    eez_sovereign == "RAA" ~ "Azores", 
    eez_sovereign == "RAM" ~ "Madeira",
    TRUE ~ eez_country_name
  )) %>%
  mutate(eez_country_name = ifelse(is.na(eez_country_name), "High seas", eez_country_name))


fao_lookup <- read.csv(here("data/model_features/deg_1_x_1/fao/fao_major_ids.csv")) %>%
  clean_names() %>%
  dplyr::select(fao_id, "fao_major_fishing_area" = "name_en")

global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv")) %>%
  dplyr::select(lon, lat, pixel_id)

access_data <- qs::qread(here("data/int/prediction_historical_data/catch_fishing_access.qs"))
access_data_high_seas <- qs::qread(here("data/int/prediction_historical_data/catch_fishing_access_high_seas.qs"))

env_grid <- env_data %>% 
  dplyr::select(lon, lat) %>% distinct()

env_data_fishing_areas <- env_data %>% 
  filter(sea_ice_present == 0) %>%
      left_join(eez_lookup)

env_grid_fishing_areas <- env_data_fishing_areas %>% 
  dplyr::select(lon, lat) %>% distinct()

```

After the models are fit, we make predictions on ALL DATA. So stage 1 is in sample predictions (since we fit the stage one model on all data), and stage two will contain out of sample predictions (since we fit the model on only data with fishing effort in it!)

 - Takes ~3.5 hours with 38 cores.. Can we speed this up?!
 
  - note: "In the three cases where flag countries were represented in Rousseau but not GFW (Azores, Madeira, and Mayotte), we used the models from these flag’s sovereign state (e.g., for Azores and Madeira we used the Portugal model). We limited the predictions of these missing flags to areas where they can fish, according to the Watson database, just like our normal methods described above."

```{r}
stage_1_path <- file.path(rdsi_dir, "prep/random_forest/stage_1_models/")
stage_1_files <- list.files(stage_1_path, full.names = TRUE)
stage_1_flags <- unique(sub(".*stage_1_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_1_files))

stage_2_path <- file.path(rdsi_dir, "prep/random_forest/stage_2_models/")
stage_2_files <- list.files(stage_2_path, full.names = TRUE)
stage_2_flags <- unique(sub(".*stage_2_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_2_files))

diff_flags_1 <- setdiff(stage_1_flags, stage_2_flags)
diff_flags_2 <- setdiff(stage_2_flags, stage_1_flags)

model_flags <- intersect(stage_1_flags, stage_2_flags) # 147

setdiff(flags, model_flags) # [1] "DOM" "RAA" "RAM" "MYT";  missing 4; these will be gapfilled with regional modelling

## MYT, RAA, and RAM will use their sovereign countries' (FRA and PRT) models and we will limit access to what Rousseau/Watson say for access rights. DOM will be filled in with regional modelling.

years <- c(1950:2017)

out_dir <- file.path(rdsi_dir, "prep/random_forest/predictions/yearly")

tasks <- CJ(flag = flags, year = years)
tasks[, out_file := file.path(out_dir, sprintf("model_preds_%s_%d.qs", flag, year))]
tasks <- tasks[!file.exists(out_file)]

data_to_run <- hist_fish_data %>%
  distinct(flag_fin, year) %>%
  left_join(tasks, by = c("year", "flag_fin" = "flag")) %>%
  filter(!is.na(out_file))

flags_to_run <- unique(data_to_run$flag_fin) #17 missing
years_to_run <- unique(data_to_run$year) # the same
flags_to_run <- setdiff(flags, flags_to_run)

cl <- makeCluster(38) 
registerDoParallel(cl)

 foreach(flag = flags_to_run, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger")) %dopar% {
    #  flag = "STP"
   
   #### Read in models 
   # read in stage 2 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/stage_2_models/"), 
  pattern = glue::glue("stage_2_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage2_model <- qs::qread(matching_files[1])  # Read the first matching file
} else if (flag %in% c("RAM", "RAA")){
  
  stage2_model <- qs::qread(file.path(rdsi_dir, "prep/random_forest/stage_2_models/", "stage_2_rf_model_full_data_PRT_24.qs"))
 } else if (flag %in% c("MYT")) {
      stage2_model <- qs::qread(file.path(rdsi_dir, "prep/random_forest/stage_2_models/", "stage_2_rf_model_full_data_FRA_24.qs"))

  }  else{
  stop("No matching file found for flag: ", flag)
}

## read in stage 1 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/stage_1_models/"), 
  pattern = glue::glue("stage_1_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage1_model <- qs::qread(matching_files[1])  # Read the first matching file
}  else if (flag %in% c("RAM", "RAA")){
  
  stage1_model <- qs::qread(file.path(rdsi_dir, "prep/random_forest/stage_1_models/", "stage_1_rf_model_full_data_PRT_27.qs"))
 } else if (flag %in% c("MYT")) {
      stage1_model <- qs::qread(file.path(rdsi_dir, "prep/random_forest/stage_1_models/", "stage_1_rf_model_full_data_FRA_27.qs"))

  } else {
  stop("No matching file found for flag: ", flag)
}


 #foreach(yr = years, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger")) %dopar% {

 for(yr in years) {
    
   ## uncheck this if you arent doing a full rerun 
   # if(file.exists(file.path(rdsi_dir, glue("prep/random_forest/predictions/yearly/model_preds_{flag}_{yr}.qs")))){
   #   cat("skipping", "exists")
   #   next()
   # }

# yr = 2005

# get combination of categories we need to run through our models
model_data_flag <- hist_fish_data %>%
  dplyr::select(flag_fin, gear, length_category, year, total_nominal_fishing_hours ) %>%
  filter(flag_fin == flag, year == yr)

access_data_loop <- access_data %>%
  filter(flag_fin == flag, 
         year == yr)

access_data_hs_loop <- access_data_high_seas %>%
  filter(flag_fin == flag, 
         year == yr)
  
distinct_cats <- model_data_flag %>%
    distinct(flag_fin, gear, length_category) 

full_data <- tidyr::crossing(env_grid_fishing_areas, distinct_cats) %>% 
  crossing(., year = yr) %>%
  left_join(env_data_fishing_areas, by = c("lon", "lat", "year")) %>%
  left_join(access_data_loop) %>% # limit to areas that each flag can access here, so that predictions won't take as long.
  left_join(access_data_hs_loop) %>%
  dplyr::select(-pixel_id) %>%
    mutate(access = ifelse(is.na(access), 0, access),
    access_fao = ifelse(is.na(access_fao), 0, access_fao)) %>% # only allow fishing where Watson says they can fish
  mutate(access = ifelse(eez_sovereign == flag, 1, access)) %>% # always allow a country to fish in its own EEZ
  mutate(access_fin = ifelse(eez_sovereign == "High seas", access_fao, access)) %>%
  filter(access_fin == 1) %>% # filter for areas where this flag actually has access to fishing
  dplyr::select(-fao_area_name) %>%
  na.omit()

if(nrow(full_data) == 0){
    cat("skipping", flag, yr, "check to make sure this is right")
  next()
}


# set.seed(123) # apparently this is unncessary
oos_preds <- full_data %>%
  mutate(pred_prop = predict(stage2_model, data = .)$predictions)

stage1_preds <- full_data %>%
  mutate(pred_presence = predict(stage1_model, data = .)$predictions[, "1"])

stage_1_preds_rescale <- stage1_preds %>%
  left_join(eez_lookup) %>%
    mutate(pred_presence_rescale = case_when(
        (flag_fin == eez_sovereign & pred_presence > 0) ~ 1,
        pred_presence >= 0.5 ~ 1, 
        TRUE ~ 0
    )) #  # make any predictions > 0 to be presence = 1, only if in the EEZ.  If not in EEZ then we use >=0.5 ~ 1
# “We prefer to err on the side of inclusion within a flag’s EEZ.”
# “We tolerate more false positives in EEZs, but prioritize precision in the high seas.”

## join stage 1 and 2 preds together and multiply 
all_preds <- oos_preds %>%
  dplyr::select(lat, lon, gear, length_category, year, flag_fin, pred_prop) %>% # probably select lat, lon, gear, length, year, flag here?
  left_join(., stage_1_preds_rescale) %>% 
    dplyr::select(lon, lat, flag_fin,gear, length_category, year, fao_id, eez_id, eez_sovereign, eez_country_name, pred_prop, pred_presence_rescale) %>% 
  mutate(pred_prop_final = pred_prop*pred_presence_rescale) %>%
  filter(pred_prop_final > 0) %>%
  filter(!is.na(pred_prop_final)) %>%
 group_by(year, flag_fin, gear, length_category) %>%
  mutate(prop_fishing_hours_cell_predict_rescaled = pred_prop_final / sum(pred_prop_final, na.rm = TRUE)) %>%
 ungroup() %>% # need to rescale the predictions to be between 0 and 1 here so that we can allocate effort
  left_join(hist_fish_data) %>%
  mutate(nom_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_nominal_fishing_hours,
         eff_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_effective_fishing_hours) %>%
  left_join(global_grid) %>%
  left_join(fao_lookup) %>%
  left_join(eez_lookup) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, gear, length_category, eez_sovereign, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours) %>%
  filter(nom_active_fishing_hours > 0) %>%
  mutate(sector = "Industrial")


if(nrow(all_preds) == 0){
    cat("skipping", flag, yr, "no predictions made...")
  next()
}

# test_preds <- all_preds %>%
#   #filter(gear == "Dredges") %>%
#   #filter(eez_sovereign != "High seas") %>%
#   dplyr::group_by(lon, lat) %>%
#   summarise(nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
#   ungroup() %>%
#   rast(., type = "xyz")
# 
# plot(test_preds)
# plot(log(test_preds+1)) # Cool!

qs::qsave(all_preds, file.path(rdsi_dir, glue("prep/random_forest/predictions/yearly/model_preds_{flag}_{yr}.qs"))) # qs is smaller

  }

}

stopCluster(cl)

```

Combine all years for flag and save 

 - only takes a minute
  - need to convert hours to days 
  - need to calculate nv
    -  `nv = nominal_effort / (days_at_sea*mean_engine_p)`
 
```{r}

days_to_hours_conversion <- qs::qread(here("data/int/hours_to_days_conversion.qs")) %>%
  rename(lon = x, lat = y) %>%
  left_join(global_grid)

nv_conversion <- qs::qread(here("data/model_features/rousseau_ind_effort_nv_conversion.qs"))


data_grid_area <- data_grid_area %>%
st_drop_geometry()

cl <- makeCluster(46)  # could probably increase this? 
registerDoParallel(cl)

foreach(flag = flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "HKG"
  
  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions/yearly/"), pattern = flag, full.names = TRUE)
  
    # Skip iteration if no files are found
  if (length(all_files_flag) == 0) next
  
  # hours / hours/day = hours * day/hours = days

  all_data_flag <- lapply(all_files_flag, qread) %>%
    bind_rows() %>%
    left_join(eez_lookup) %>%
    mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, flag_country_name, gear, length_category, eez_sovereign, eez_country_name, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours, sector) %>%
    left_join(nv_conversion) %>%
          mutate(nv = nom_active_fishing_hours/(days_at_sea*mean_engine_p)) %>%
    left_join(., days_to_hours_conversion) %>%
    mutate(nom_active_fishing_days = nom_active_fishing_hours/mean,
           eff_active_fishing_days = eff_active_fishing_hours/mean) %>%
    dplyr::select(-mean, -days_at_sea, -mean_engine_p, -nom_active_days, -eff_active_days, -p, -gt) %>%
        rename(flag_country_iso3c = flag_fin, eez_sovereign_iso3c = eez_sovereign, eez_sovereign_name = eez_country_name, fao_fishing_id = fao_id) %>%
    left_join(data_grid_area) %>%
    mutate(pixel_area_km2 = pixel_area_m2/1000000) %>%
    mutate(eff_days_km2 = eff_active_fishing_days/pixel_area_km2,
           nom_days_km2 = nom_active_fishing_days/pixel_area_km2,
           eff_hours_km2 = eff_active_fishing_hours/pixel_area_km2,
           nom_hours_km2 = nom_active_fishing_hours/pixel_area_km2,
           nv_km2 = nv/pixel_area_km2) # calculate hours per km2 here too
  
  qs::qsave(all_data_flag, file.path(rdsi_dir, glue("prep/random_forest/predictions/model_preds_1950_2017_{flag}.qs")))
}

stopCluster(cl)


test_preds <- qs::qread("/home/ubuntu/data_storage/prep/random_forest/predictions/model_preds_1950_2017_IND.qs") %>%
  filter(year == 2017) %>%
  dplyr::group_by(lon, lat) %>%
  summarise(nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
  ungroup() %>% 
  left_join(data_grid_area) %>%
  mutate(hours_km2 = nom_active_fishing_hours/(pixel_area_m2/1000000)) %>%
  dplyr::select(lon, lat, hours_km2) %>%
  rast(., type = "xyz")

plot(test_preds)
plot(log(test_preds+1)) # Cool!

```




