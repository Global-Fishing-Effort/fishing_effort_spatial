---
title: "Save data for Zenodo publishing"
output: html_document
date: "2024-12-11"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(glue)
library(qs)
library(here)
library(countrycode)
library(strex)
library(data.table)
library(sf)

source(here("R/dir.R"))


  global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv"))
mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

data_grid_area <- global_grid %>%
    st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 

```


Save csv files to upload to Zenodo and the app 

 - We need to grab any gapfilled flags that are not in the flag level modelling from the regional level modelling 
 
 We gap fill using regional models where 1) a flag country is not included at all in the AIS data (e.g., DOM, MYT, RAA, RAM), where a flag country has less than 100 observations across all years of data (e.g., GLP, COG, COG, JAM), or 3) where the flag-specific model was unable to predict any presence for a specific flag/gear/length combination (e.g., GTM bottom trawls 2015-2017). 


```{r}

  modelled_flags_original <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/predictions_flag_no_access/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")

  modelled_flags_regional <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/predictions_regional/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")
  
flags_to_gapfill <- setdiff(modelled_flags_regional, modelled_flags_original)


all_flags <- c(modelled_flags_original, flags_to_gapfill)

low_sample_flags <- readRDS(here("data/model_features/prepared_data_1deg.rds")) %>%
  group_by(flag_fin) %>%
  summarise(n_obs = n()) %>%
  ungroup() %>%
  filter(flag_fin %in% all_flags) %>%
  filter(n_obs < 100) %>%
  pull(flag_fin) %>%
  unique()
                

cl <- makeCluster(24)  # could probably increase this? 
registerDoParallel(cl)


foreach(flag = all_flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "TGO"
  
  
  all_files_flag_original <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions_flag_no_access/"), pattern = flag, full.names = TRUE)
  all_files_flag_regional_gf <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions_regional/"), pattern = flag, full.names = TRUE)

  
  #   # Skip iteration if no files are found
  # if (length(all_files_flag) == 0) next
  

  all_data_flag_original <- lapply(all_files_flag_original, qread) %>%
    bind_rows() %>%
    mutate(data_type = "flag model")
  
  if(flag == "GAB"){
    
    all_data_flag_original <- all_data_flag_original %>%
      filter(year != 2017)
  }

  
  all_data_flag_regional_gf <- lapply(all_files_flag_regional_gf, qread) %>%
    bind_rows()  %>%
    mutate(data_type = "regional model")
  
    if(nrow(all_data_flag_original) == 0|flag %in% c(low_sample_flags)){
    
    all_data_flag_original <- all_data_flag_regional_gf %>%
      mutate(nom_active_fishing_hours = 0, eff_active_fishing_hours = 0, nom_active_fishing_days = 0, eff_active_fishing_days = 0, eff_days_km2 = 0, nom_days_km2 = 0, eff_hours_km2 = 0, nom_hours_km2 = 0, nv = 0, nv_km2 = 0, data_type = NA)
    
    }
  
if(nrow(all_data_flag_regional_gf) == 0){
    
    all_data_flag_regional_gf <- all_data_flag_original %>%
      mutate(nom_active_fishing_hours = 0, eff_active_fishing_hours = 0, nom_active_fishing_days = 0, eff_active_fishing_days = 0, eff_days_km2 = 0, nom_days_km2 = 0, eff_hours_km2 = 0, nom_hours_km2 = 0, nv = 0, nv_km2 = 0, data_type = NA)
    
  }
  
  original_cats <- all_data_flag_original %>%
    filter(nom_active_fishing_hours > 0) %>%
    distinct(year, flag_country_iso3c, gear, length_category) 
  
  regional_cats <- all_data_flag_regional_gf %>%
    filter(nom_active_fishing_hours > 0) %>%
    distinct(year, flag_country_iso3c, gear, length_category) 
  
  missing_cats <- regional_cats %>%
   anti_join(original_cats, by = c("year", "flag_country_iso3c", "gear", "length_category"))

  data_to_add <- all_data_flag_regional_gf %>%
    semi_join(missing_cats, by = c("flag_country_iso3c", "year", "gear", "length_category"))
  
  # test <- data_to_add %>%
  #   filter(nom_active_fishing_hours > 0) %>%
  #   distinct(year, flag_country_iso3c, gear, length_category)
  
  all_data_fin <- all_data_flag_original %>%
    filter(nom_active_fishing_hours > 0) %>%
    rbind(data_to_add) %>%
    mutate(flag_country_name = case_when(
      flag_country_iso3c == "RAA" ~ "Azores", 
      flag_country_iso3c == "RAM" ~ "Madeira", 
      flag_country_iso3c == "COG" ~ "Republic of the Congo",
      flag_country_iso3c == "COD" ~ "Democratic Republic of the Congo",
      TRUE ~ flag_country_name
    )) %>%
    dplyr::select(-pixel_area_m2, -pixel_id, -eff_days_km2, -eff_hours_km2, -nom_days_km2, -nom_hours_km2, -nv_km2)
  
  
# 
# test <- all_data_fin %>%
#  filter(year == 2017) %>%
#   group_by(lon, lat) %>%
#   summarise(eff = sum(nom_active_fishing_hours)) %>%
#   ungroup() %>%
#   dplyr::select(lon, lat, eff) %>%
#   rast(., type = "xyz")
# 
# plot(test)
# plot(log(test+1))

  
  write.csv(all_data_fin, file.path(rdsi_dir, glue("prep/random_forest/zenodo_data/mapped_by_flag_country/model_preds_1950_2017_{flag}.csv")), row.names = FALSE)
}

stopCluster(cl)


## save as one large csv

  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/zenodo_data/mapped_by_flag_country/"), full.names = TRUE)

    all_data <- lapply(all_files_flag, fread) %>%
      bind_rows()
    
fwrite(all_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/mapped_industrial_effort_predictions_1950_2017.csv"), row.names = FALSE)

all_data_grouped <- all_data %>% 
  group_by(year, flag_country_iso3c, flag_country_name, gear, length_category, eez_sovereign_iso3c, eez_sovereign_name, fao_fishing_id, fao_major_fishing_area, sector, model_type = data_type) %>%
  summarise(eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE)) %>%
  ungroup()


fwrite(all_data_grouped, file.path(rdsi_dir, "prep/random_forest/zenodo_data/industrial_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"), row.names = FALSE)



  all_data_grouped <- fread(file.path(rdsi_dir, "prep/random_forest/zenodo_data/industrial_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"))
  
all_data_grouped_2 <- all_data_grouped %>% 
  group_by(year, flag_country_iso3c, flag_country_name, gear, length_category) %>%
    summarise(modeled_eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            modeled_eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            modeled_nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            modeled_nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE)) %>%
  ungroup() %>%
    mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores",     
          flag_country_iso3c == "COG" ~ "Republic of the Congo",
      flag_country_iso3c == "COD" ~ "Democratic Republic of the Congo",
          TRUE ~ flag_country_name
  ))

hist_fish_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      total_nominal_fishing_days = sum(nom_active, na.rm = TRUE),
      total_effective_fishing_days = sum(eff_active, na.rm = TRUE)
    ) %>%
  ungroup() %>%
    dplyr::select(flag_country_iso3c = flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours, total_nominal_fishing_days, total_effective_fishing_days) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_country_iso3c, origin = "iso3c", destination = "country.name")) %>%
  mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores", 
                flag_country_iso3c == "COG" ~ "Republic of the Congo",
      flag_country_iso3c == "COD" ~ "Democratic Republic of the Congo",
          TRUE ~ flag_country_name
  )) %>% 
  left_join(all_data_grouped_2) %>%
  mutate(modeled_eff_active_fishing_hours = ifelse(is.na(modeled_eff_active_fishing_hours), 0, modeled_eff_active_fishing_hours),
         modeled_eff_active_fishing_days = ifelse(is.na(modeled_eff_active_fishing_days), 0, modeled_eff_active_fishing_days), 
         modeled_nom_active_fishing_hours = ifelse(is.na(modeled_nom_active_fishing_hours), 0, modeled_nom_active_fishing_hours),
         modeled_nom_active_fishing_days = ifelse(is.na(modeled_nom_active_fishing_days), 0, modeled_nom_active_fishing_days)) %>%
  mutate(proportion_hours_modeled = modeled_nom_active_fishing_hours/total_nominal_fishing_hours)

missing_data <- hist_fish_data %>%
  filter(proportion_hours_modeled != 1) %>%
  filter(proportion_hours_modeled < 0.9999) # should be 0 after our gapfilling
 
fwrite(hist_fish_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/known_industrial_effort_rousseau.csv"), row.names = FALSE)


fwrite(missing_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/effort_not_modelled.csv"), row.names = FALSE)

test <- fread(file.path(rdsi_dir, "prep/random_forest/zenodo_data/effort_not_modelled.csv"))



test <- hist_fish_data %>% filter(flag_country_iso3c == "UKR", year == 1950)

sum(test$total_nominal_fishing_hours) # 
sum(test$modeled_nom_active_fishing_hours) # 


```

How much was gapfilled 

```{r}
all_data_grouped <- fread(file.path(rdsi_dir, "prep/random_forest/zenodo_data/industrial_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"))

gapfill_df <- all_data_grouped %>%
  group_by(flag_country_name, year, model_type) %>%
  summarise(eff = sum(nom_active_fishing_days, na.rm = TRUE)) %>% 
              ungroup() %>%
  pivot_wider(names_from = "model_type", values_from = eff) %>%
  janitor::clean_names() %>%
mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

sum(gapfill_df$regional_model)/sum(all_data_grouped$nom_active_fishing_hours)

gapfill_df %>% filter(year == 2017) %>% pull(regional_model) %>% sum()/sum(all_data_grouped$nom_active_fishing_hours)


full_predictions <- gapfill_df %>%
  filter(flag_model == 0, regional_model > 0) %>%
  filter(!(flag_country_name %in% c("Azores", "Madeira", "Mayotte", "Dominican Republic")))
sum(full_predictions$regional_model)/sum(all_data_grouped$nom_active_fishing_hours)

low_sample_flags <- readRDS(here("data/model_features/prepared_data_1deg.rds")) %>%
  group_by(flag_fin) %>%
  summarise(n_obs = n()) %>%
  ungroup() %>%
  filter(flag_fin %in% unique(all_data_grouped$flag_country_iso3c)) %>%
  filter(n_obs < 100) %>%
  pull(flag_fin) %>%
  unique()
              

partial_preds <- gapfill_df %>%
  filter(flag_model >0, regional_model > 0)
sum(partial_preds$regional_model)/sum(all_data_grouped$nom_active_fishing_hours)

```


Figure out why HKG is so large


```{r}
test_hkg_regional <- qread(file.path(rdsi_dir, "prep/random_forest/predictions_regional/model_preds_1950_2017_HKG.qs"))

test_hkg_regular <- qread(file.path(rdsi_dir, "prep/random_forest/predictions/model_preds_1950_2017_HKG.qs"))

test_hkg_regular_2017 <- test_hkg_regular %>%
  filter(year == 2017) %>%
  group_by(lon, lat) %>% 
  summarise(nom = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
  ungroup() 

rast(test_hkg_regular_2017, type = "xyz") %>% plot() # interesting 


test_hkg_regional_2017 <- test_hkg_regional %>%
  filter(year == 2017) %>%
  group_by(lon, lat) %>% 
  summarise(nom = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
  ungroup() 

rast(test_hkg_regional_2017, type = "xyz") %>% plot() # ok, A LOT more spread out. Does HKG actually have access to those places according to Watson? Is something going wrong in our regional predictions?  


test_hkg_regional_2017 <- test_hkg_regional %>%
  filter(eez_sovereign_iso3c == "HKG") # hmmmm 0. Feels like there should be some allocated there. Are we using the updated EEZ file? 


```

```{r}
test_aus <- fread(file.path(rdsi_dir, "prep/random_forest/zenodo_data/mapped_by_flag_country/model_preds_1950_2017_GAB.csv"))

test_pixel <- test_aus %>%
  distinct(lon, lat, pixel_area_km2)

test_2 <- test_aus %>%
 filter(year == 2017) %>%
  group_by(lon, lat) %>%
  summarise(eff = sum(nom_active_fishing_hours)) %>%
  ungroup() %>%
  full_join(data_grid_area %>% st_drop_geometry) %>%
  mutate(eff = ifelse(is.na(eff), 0, eff)) %>%
  mutate(eff_km2 = eff/(pixel_area_m2/1000000)) %>%
  dplyr::select(lon, lat, eff_km2) %>%
  rast(., type = "xyz")

plot(test_2)
plot(log(test_2+1))

```

Manually comparing to SAUP 2017

Potential problem flags: 

CHN (not dispersed enough, consider rerunning without access constraints), ECU (not dispersed enough), Fiji (not dispersed enough), GBR (not dispersed enough), GLP (too dispersed), GRC (not dispersed enough), IDN (not dispersed enough), ITA (not dispersed enough, need Africa), JPN (need Russia), Montenegro (too dispersed), MYS (not dispersed enough), NOR (need antarctica), RUS (need antarctica), THA (not dispersed enough), UKR (need more antarctica?), VNM (not dispersed enough)

Look over after removing access layer for flag modelling: 

CHN (potentially not dispersed enough), Ecuador (not enough DFW), GTM (not enough fishing in their own EEZ for 2017), GRC (need fishing in West Africa), IDN (not dispersed enough), JPN (need more Russia?), MYS (not dispersed enough), NOR (need Antarctica), STP (>2014 fishing in China? Not enough in EEZ), THA (not dispersed enough), VNM (not dispersed enough) 
