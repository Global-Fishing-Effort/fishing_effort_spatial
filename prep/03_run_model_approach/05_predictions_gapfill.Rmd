---
title: "Predict props to cells per flag, year, gear, length using the regional models"
output: html_document
date: "2024-12-11"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(progress)
library(pryr)  # for memory tracking
library(glue)
library(qs)
library(here)
library(janitor)
library(arrow)
library(countrycode)
library(sf)
library(strex)
library(ranger)
library(randomForest)
library(parallel)

source(here("R/dir.R"))
```

## Functions to prepare enviro and effort data  

```{r}
elnino <- read.csv(here("data/model_features/enso_index.csv"))

pdo <- read.csv(here("data/model_features/pdo_index.csv"))

world_bank <- read.csv(here("data/model_features/world_bank_regions.csv"))

gfi_df <- read.csv(here("data/model_features/global_fishing_index_governance.csv"))
  
# Load prepared data
model_data <- readRDS(here("data/model_features/prepared_data_1deg.rds")) %>%
  mutate(year = as.numeric(year)) # i think we need to adjust the prepared data to include cells which have no fishing effort in them. We can do this in the loop below? 

## read in environmental variables

  global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv"))
  
  ocean_data <- read.csv(here("data/model_features/deg_1_x_1/errdap_chl.csv")) %>%
  left_join(read.csv(here("data/model_features/deg_1_x_1/errdap_sst.csv")), by = c("pixel_id", "year")) %>% 
  left_join(read.csv(here("data/model_features/deg_1_x_1/remss_wind.csv")), by = c("pixel_id", "year")) %>%
  filter(year %in% c(2015:2024)) 
  
  ocean_data_historical <- qs::qread(here("data/int/prediction_historical_data/one_degree/chl_yearly_1950_2014.qs")) %>%
    dplyr::select(-pixel_area_m2) %>%
  left_join(qs::qread(here("data/int/prediction_historical_data/one_degree/sst_yearly_1950_2014.qs")) %>%  dplyr::select(-pixel_area_m2), by = c("pixel_id", "year")) %>% 
  left_join(qs::qread(here("data/int/prediction_historical_data/one_degree/wind_yearly_1950_2014.qs")) %>% mutate(year = as.numeric(year)) %>% dplyr::select(-pixel_area_m2), by = c("pixel_id", "year"))

  # why are there some NAs? They are at the poles; southern ocean and arctic. Probably don't need to worry about these for most countries.

  ocean_data_all <- ocean_data %>%
    rbind(ocean_data_historical)

  spatial_data <- global_grid %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/gfw_static_spatial_measures.csv")) %>% dplyr::select(-lat, -lon), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/mesopelagiczones/mesopelagiczones_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/eez/eez_fix.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/fao/fao_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/oceans_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/seamounts.csv")), by = "pixel_id") %>% 
   crossing(., year = c(1950:2024)) 
  
      gfw_reception_data <- read.csv(here("data/model_features/deg_1_x_1/gfw_reception_quality.csv"))

      sea_ice_df <- qs::qread(here("data/model_features/deg_1_x_1/sea_ice_features_lit.qs"))

  env_data <- spatial_data %>%
            left_join(sea_ice_df) %>%
    left_join(ocean_data_all) %>% # cool.
    left_join(elnino) %>%
    left_join(pdo) %>%
    left_join(gfw_reception_data) %>%
    left_join(world_bank, by = c("eez_id")) %>%
    mutate(eez_region_world_bank_7 = ifelse(eez_id %in% c("High seas", "Land"), "High seas", eez_region_world_bank_7)) %>% 
    left_join(gfi_df, by = c("eez_sovereign" = "flag_fin")) %>% # add in global fishing index data here
    mutate(gov_score = ifelse(eez_id >= 99999 & is.na(gov_score), "high_seas", gov_score)) %>%
        mutate(gov_score = ifelse(eez_id < 99999 & is.na(gov_score), "no_data", gov_score)) %>%
    dplyr::select(-eez_sovereign, -nearest_seamount_id) %>% 
    distinct()  %>%
    dplyr::select(-geometry_wkt)

mollweide_projection <- "+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs"

data_grid_area <- global_grid %>%
    st_as_sf(wkt = "geometry_wkt",
           crs = "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")%>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES", "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  st_transform(mollweide_projection) %>%
  mutate(pixel_area_m2 = st_area(geometry_wkt)%>%
           units::drop_units()) 

```

```{r}

rousseau_regions <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/SAUPtoCountry.csv") %>%
  dplyr::select(-X) %>%
  rename(region = Region) 

fix_landlocked <- rousseau_regions %>%
  filter(region == "Landlocked") %>%
  mutate(region = case_when(
    Country == "AFG" ~ "MidEast",
    Country == "AND" ~ "Europe",
    Country == "AZE" ~ "MidEast",
    Country == "AUT" ~ "Europe",
    Country == "ARM" ~ "MidEast",
    Country == "BTN" ~ "SouthEastAsia",
    Country == "BOL" ~ "LatinAmerica",
    Country == "BWA" ~ "SubAfrica",
    Country == "BDI" ~ "SubAfrica",
    Country == "BLR" ~ "Europe",
    Country == "CAF" ~ "SubAfrica",
    Country == "TCD" ~ "NWAfrica",
    Country == "CSK" ~ "Europe",   # Historical, treat as Europe if included
    Country == "CZE" ~ "Europe",
    Country == "ETH" ~ "SubAfrica",
    Country == "HUN" ~ "Europe",
    Country == "KAZ" ~ "MidEast",
    Country == "KGZ" ~ "MidEast",
    Country == "LAO" ~ "SouthEastAsia",
    Country == "LSO" ~ "SubAfrica",
    Country == "LIE" ~ "Europe",
    Country == "LUX" ~ "Europe",
    Country == "MWI" ~ "SubAfrica",
    Country == "MLI" ~ "NWAfrica",
    Country == "MNG" ~ "NorthEastAsia",
    Country == "MDA" ~ "Europe",
    Country == "NPL" ~ "SouthEastAsia",
    Country == "NER" ~ "NWAfrica",
    Country == "PRY" ~ "LatinAmerica",
    Country == "RWA" ~ "SubAfrica",
    Country == "SMR" ~ "Europe",
    Country == "SVK" ~ "Europe",
    Country == "SWZ" ~ "SubAfrica",
    Country == "CHE" ~ "Europe",
    Country == "TJK" ~ "MidEast",
    Country == "TKM" ~ "MidEast",
    Country == "UGA" ~ "SubAfrica",
    Country == "MKD" ~ "Europe",
    Country == "BFA" ~ "NWAfrica",
    Country == "UZB" ~ "MidEast",
    Country == "SRB" ~ "Europe",
    Country == "ZMB" ~ "SubAfrica",
    TRUE ~ region
  ))

rousseau_fix <- rousseau_regions %>%
  filter(region != "Landlocked") %>%
  rbind(fix_landlocked) %>%
  dplyr::select(-SAUP) %>%
  filter(region  != "Unknown") %>%
    add_row(Country = "ATF", region = "IslandNations") %>%
    add_row(Country = "VAT", region = "Europe") %>%
    add_row(Country = "BES", region = "Caribbean") %>%
    add_row(Country = "CCK", region = "IslandNations")

  hist_fish_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    dplyr::select(flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
    left_join(rousseau_fix, by = c("flag_fin" = "Country")) %>%
    mutate(flag_country_name = case_when(
      flag_fin == "RAA" ~ "Azores",
      flag_fin == "RAM" ~ "Madeira",
      TRUE ~ flag_country_name
    ))
  test <- hist_fish_data %>% filter(is.na(flag_country_name))

  
flags <- unique(hist_fish_data$flag_fin) # get the flags we need to run models for # 147 of them

# env_grid <- env_data %>% 
#   dplyr::select(lon, lat) %>% distinct()

```


Read in EEZ id and FAO id lookup tables so we can save with the actual iso3c and FAO id numbers

```{r}

eez_lookup <- read.csv(here("data/model_features/deg_1_x_1/eez/eez_lookup_fix.csv")) %>%
  clean_names() %>%
  mutate(eez_country_name = countrycode(eez_sovereign, origin = "iso3c", destination = "country.name")) %>%
  mutate(eez_country_name = case_when(
    eez_sovereign == "RAA" ~ "Azores", 
    eez_sovereign == "RAM" ~ "Madeira",
    TRUE ~ eez_country_name
  )) %>%
  mutate(eez_country_name = ifelse(is.na(eez_country_name), "High seas", eez_country_name))

fao_lookup <- read.csv(here("data/model_features/deg_1_x_1/fao/fao_major_ids.csv")) %>%
  clean_names() %>%
  dplyr::select(fao_id, "fao_major_fishing_area" = "name_en")

global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv")) %>%
  dplyr::select(lon, lat, pixel_id)


env_data_fishing_areas <- env_data %>% 
  filter(sea_ice_present == 0) %>%
      left_join(eez_lookup)

env_grid_fishing_areas <- env_data_fishing_areas %>% 
  dplyr::select(lon, lat) %>% distinct()

# load access data 
access_data_loop <- qs::qread(here("data/int/prediction_historical_data/catch_fishing_access.qs")) %>%
  distinct()
access_data_high_seas_loop <- qs::qread(here("data/int/prediction_historical_data/catch_fishing_access_high_seas.qs"))

```

First lets check to see what predictions need to be gapfilled. We'll do this by reading in the flag country predictions and comparing to the Rousseau data. If any effort is missing for a flag, we will run the predictions here for gapfilling. 

```{r}

 modelled_flags_original <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/predictions/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")

  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions/"), full.names = TRUE)

    all_data <- lapply(all_files_flag[-148], qread) %>%
      bind_rows()

all_data_grouped_2 <- all_data %>% 
  group_by(year, flag_country_iso3c, flag_country_name, gear, length_category) %>%
    summarise(modeled_eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            modeled_eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            modeled_nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            modeled_nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE)) %>%
  ungroup() %>%
    mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores", 
          TRUE ~ flag_country_name
  ))

check_rousseau_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      total_nominal_fishing_days = sum(nom_active, na.rm = TRUE),
      total_effective_fishing_days = sum(eff_active, na.rm = TRUE)
    ) %>%
  ungroup() %>%
    dplyr::select(flag_country_iso3c = flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours, total_nominal_fishing_days, total_effective_fishing_days) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_country_iso3c, origin = "iso3c", destination = "country.name")) %>%
  mutate(flag_country_name = case_when(
          flag_country_iso3c == "RAM" ~ "Madeira",
          flag_country_iso3c == "RAA" ~ "Azores", 
          TRUE ~ flag_country_name
  )) %>% 
  left_join(all_data_grouped_2) %>%
  mutate(modeled_eff_active_fishing_hours = ifelse(is.na(modeled_eff_active_fishing_hours), 0, modeled_eff_active_fishing_hours),
         modeled_eff_active_fishing_days = ifelse(is.na(modeled_eff_active_fishing_days), 0, modeled_eff_active_fishing_days), 
         modeled_nom_active_fishing_hours = ifelse(is.na(modeled_nom_active_fishing_hours), 0, modeled_nom_active_fishing_hours),
         modeled_nom_active_fishing_days = ifelse(is.na(modeled_nom_active_fishing_days), 0, modeled_nom_active_fishing_days)) %>%
  mutate(proportion_hours_modeled = modeled_nom_active_fishing_hours/total_nominal_fishing_hours)

missing_data <- check_rousseau_data %>%
  filter(proportion_hours_modeled != 1) %>%
  filter(proportion_hours_modeled < 0.9999)

flags_missing <- unique(missing_data$flag_country_iso3c) # 22 flags missing

regions_missing_df <- hist_fish_data %>% 
  filter(flag_fin %in% c(flags_missing)) %>%
  distinct(flag_fin, region)
  
regions_missing <- hist_fish_data %>% 
  filter(flag_fin %in% c(flags_missing)) %>%
  pull(region) %>%
  unique() # ok only 7 regions missing, so that's good 
  

years_missing <- unique(missing_data$year) # all years missing, beacuse of Hong Kong for example...

regions_missing_df_2 <- hist_fish_data %>%
  filter(flag_fin %in% c(flags_missing)) %>%
  distinct(flag_fin, year)
```

After the models are fit, we make predictions on ALL DATA. So stage 1 is in sample predictions (since we fit the stage one model on all data), and stage two will contain out of sample predictions (since we fit the model on only data with fishing effort in it!)

 - Takes 4 hours with no parallelization. If parallelized, would probably take half an hour. 

```{r}

years <- c(1950:2017)

## read each model into a list upfront:

regions_missing_string <- paste0(regions_missing, collapse = "|")

all_models_s1 <- lapply(list.files(file.path(rdsi_dir, "prep/random_forest/stage_1_models_regional/"), full.names = TRUE, pattern = glue("{regions_missing_string}")), qread)
names(all_models_s1) <- regions_missing

all_models_s2 <- lapply(list.files(file.path(rdsi_dir, "prep/random_forest/stage_2_models_regional/"), full.names = TRUE, pattern = glue("{regions_missing_string}")), qread)
names(all_models_s2) <- regions_missing


# cl <- parallel::makeCluster(20)  
# doParallel::registerDoParallel(cl)
  
# foreach(flag = flags_missing, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger", "tidyr")) %dopar% {
# foreach(yr = years, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue", "ranger")) %dopar% {
for(flag in flags_missing){ 
#  flag = "WLF"
  
     flag_region <- regions_missing_df %>%
     filter(flag_fin == flag) %>%
     pull(region) %>%
     unique()
   
   stage2_model <- all_models_s2[[glue("{flag_region}")]]
   
   stage1_model <- all_models_s1[[glue("{flag_region}")]]
   
for(yr in years) {
# flag = "DOM"
# yr = 1959

    # if(file.exists(file.path(glue("/home/ubuntu/data_storage/prep/random_forest/predictions_regional/yearly/model_preds_{flag}_{yr}.qs")))){
    #   cat("skipping bc file exists")
    #   next()
    # }
    
# get combination of categories we need to run through our models
model_data_flag <- hist_fish_data %>%
  dplyr::select(flag_fin, gear, length_category, year, total_nominal_fishing_hours, region) %>%
  filter(flag_fin == flag, year == yr)
  
distinct_cats <- model_data_flag %>%
    distinct(flag_fin, gear, length_category) 

full_data <- tidyr::crossing(env_grid_fishing_areas, distinct_cats) %>%
  mutate(year = yr) %>%
  left_join(env_data_fishing_areas, by = c("lon", "lat", "year")) %>%
  dplyr::select(-pixel_id) %>% 
  left_join(access_data_loop) %>%
  left_join(access_data_high_seas_loop) %>%
  mutate(access = ifelse(is.na(access), 0, access),
    access_fao = ifelse(is.na(access_fao), 0, access_fao)) %>% # only allow fishing where Watson says they can fish
  mutate(access = ifelse(eez_sovereign == flag, 1, access)) %>% # always allow a country to fish in its own EEZ
  mutate(access_fin = ifelse(eez_sovereign == "High seas", access_fao, access)) %>%
  filter(access_fin == 1) # filter for areas where this flag actually has access to fishing

if(nrow(full_data) == 0){
    cat("skipping", flag, yr, "check to make sure this is right")
  next()
}


oos_preds <- full_data %>%
  mutate(pred_prop = predict(stage2_model, data = .)$predictions, num.threads = 1)


## make stage 1 predictions and apply fishing access filter 
stage_1_preds_rescale <- full_data %>%
  mutate(pred_presence = predict(stage1_model, data = .)$predictions[, "1"], num.threads = 1) %>%
  mutate(pred_presence = ifelse(is.na(pred_presence), 0, pred_presence)) %>%
  mutate(pred_presence_access = access_fin*pred_presence) %>%
    mutate(pred_presence_rescale = ifelse(pred_presence_access > 0, 1, 0)) 

if(flag == "RAA" & yr %in% c(2015:2016)){ # for some reason 2016 and 2017 are throwing no predictions for Azores...
  
  stage_1_preds_rescale <- stage_1_preds_rescale %>%
    mutate(pred_presence_rescale = ifelse(eez_sovereign == "RAA", 1, pred_presence_rescale))
  
} 

   # make any predictions > 0 to be presence = 1, even if less than 0.5. This should work in almost all cases, but if it doesn't, then we apply the below methods:

#### Now fill any remaining gaps (should be very rare) by using the same predictions per gear or length category
  # NOTE July 14; I don't think we need this any longer, but will keep in just in case. 
## We predict fishing presence probabilities for each combination of flag state, gear type, and vessel length category using the stage-one model. Following this, we applied a rescaling step to convert predicted probabilities to binary presence–absence, incorporating additional assumptions to account for potential fishing within national EEZs, including cases where predicted probabilities were low but domestic fishing activity was expected. To account for potential underprediction of fishing presence in specific flag–gear–length category combinations where no presence was predicted, but there is effort reported, we applied a hierarchical gap-filling procedure based on broader gear-level patterns within the flag country's fishing fleet. In cases where all predicted presence values for a given flag–gear–length category combination were zero, but other length categories within the same flag–gear combination exhibited predicted presence, we reassigned the presence predictions from the flag-gear combination with the most predictions to the all-zero category. This approach assumes that when fishing is predicted for a given gear type and flag state, similar spatial patterns are likely for other vessel size classes using the same gear, even if direct predictions were absent. If there were still flag-gear-length combinations with no predicted presence, we appleid the same approach, but focusing on length categories, rather than gear. That is, we assume that when fishing is predicted for a given vessel length and flag state, similar spatial patters are liekly for other vessel sizes, regardless of gear type. 
  

# Summarize max presence by length category
n_preds_df <- stage_1_preds_rescale %>%
  dplyr::group_by(flag_fin, gear, length_category) %>%
  summarise(
    n_preds = sum(pred_presence_rescale > 0),
    .groups = "drop"
  ) %>%
  ungroup()

best_lc <- stage_1_preds_rescale %>%
  group_by(flag_fin, gear, length_category) %>%
  summarise(
    n_preds = sum(pred_presence_rescale > 0),
    .groups = "drop"
  ) %>%
  group_by(flag_fin, gear) %>%
  slice_max(order_by = n_preds, n = 1, with_ties = FALSE) %>%
  rename(best_length_category = length_category)

preds_for_gf <- stage_1_preds_rescale %>%
  group_by(lon, lat, flag_fin, gear) %>%
    mutate(
         max_pred_gear_rescale = max(pred_presence_rescale, na.rm = TRUE)) %>%
  ungroup() %>%
  left_join(best_lc) %>%
  filter(length_category == best_length_category) %>% # select the length category with the most predictions to use for gapfilling
  dplyr::select(lon, lat, flag_fin, gear, max_pred_gear_rescale)

stage_1_preds_gf <- stage_1_preds_rescale %>%
  dplyr::select(lon, lat, flag_fin, gear, length_category, year, fao_id, eez_id, eez_sovereign, pred_presence, pred_presence_rescale) %>%
  left_join(preds_for_gf) %>%
  left_join(n_preds_df) %>%
  mutate(
    pred_presence_gf = case_when(
      pred_presence_rescale == 0 & max_pred_gear_rescale > 0 & n_preds == 0 ~ max_pred_gear_rescale, # only gapfill if there are no predictions at all in this gear/vessel type
      TRUE ~ pred_presence_rescale
    )
  )

## now we need to fill in any that weren't filled in before by gapfilling based on length instead of gear
n_preds_df <- stage_1_preds_gf %>%
  group_by(flag_fin, gear, length_category) %>%
  summarize(
    n_preds = sum(pred_presence_gf > 0),
    .groups = "drop"
  ) %>%
  ungroup()

best_lc <- stage_1_preds_gf %>%
  group_by(flag_fin, gear, length_category) %>%
  summarize(
    n_preds = sum(pred_presence_gf > 0),
    .groups = "drop"
  ) %>%
  group_by(flag_fin, length_category) %>%
  mutate(max_n_preds = max(n_preds)) %>%
  ungroup() %>%
  filter(n_preds == max_n_preds) %>%
  rename(best_length_category = length_category,
         best_gear_cat = gear) %>%
  dplyr::select(-max_n_preds)

preds_for_gf <- stage_1_preds_gf %>%
    right_join(best_lc) %>%
  group_by(lon, lat, flag_fin, length_category) %>%
    summarise(
         max_pred_gear_rescale = max(pred_presence_gf, na.rm = TRUE)) %>%
  ungroup()

stage_1_preds_gf_2 <- stage_1_preds_gf %>%
  dplyr::select(lon, lat, flag_fin, gear, length_category, year, fao_id, eez_id, eez_sovereign, pred_presence, pred_presence_rescale,
                pred_presence_gf) %>%
  left_join(preds_for_gf) %>%
  left_join(n_preds_df) %>%
  mutate(
    pred_presence_gf = case_when(
      pred_presence_gf == 0 & max_pred_gear_rescale > 0 & n_preds == 0 ~ max_pred_gear_rescale, # only gapfill if there are no predictions at all in this gear/vessel type
      TRUE ~ pred_presence_gf
    )
  )

## join stage 1 and 2 preds together and multiply 
all_preds <- oos_preds %>%
    # dplyr::select(lon, lat, flag_fin,gear, length_category, year, fao_id, eez_id, eez_sovereign, pred_prop) %>% 
   # left_join(., stage_1_preds_rescale) %>% 
     left_join(., stage_1_preds_gf_2) %>% 
   dplyr::select(lon, lat, flag_fin,gear, length_category, year, fao_id, eez_id, eez_sovereign, pred_prop, pred_presence_gf) %>% 
  mutate(pred_prop_final = pred_prop*pred_presence_gf) %>%
  filter(pred_prop_final > 0) %>%
  filter(!is.na(pred_prop_final)) %>%
 group_by(year, flag_fin, gear, length_category) %>%
  mutate(prop_fishing_hours_cell_predict_rescaled = pred_prop_final / sum(pred_prop_final, na.rm = TRUE)) %>%
 ungroup() %>% # need to rescale the predictions to be between 0 and 1 here so that we can allocate effort
  left_join(hist_fish_data) %>%
  mutate(nom_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_nominal_fishing_hours,
         eff_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_effective_fishing_hours) %>%
  left_join(global_grid) %>%
  left_join(fao_lookup) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, gear, length_category, eez_sovereign, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours) %>%
  filter(nom_active_fishing_hours > 0) %>%
  mutate(sector = "Industrial")

if(nrow(all_preds) == 0){
    cat("skipping", flag, yr, "no predictions made...")
  next()
}

# test_preds <- all_preds %>%
#   # filter(gear == "Trawl_Midwater_or_Unsp") %>%
#   # filter(eez_sovereign == "USA") %>%
#   dplyr::group_by(lon, lat) %>%
#   summarise(nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
#   ungroup() %>%
#   rast(., type = "xyz")
# 
# plot(test_preds)
# plot(log(test_preds+1)) # Cool!


qs::qsave(all_preds, file.path(rdsi_dir, glue("prep/random_forest/predictions_regional/yearly/model_preds_{flag}_{yr}.qs"))) # qs is smaller

    }
}

# stopCluster(cl)

```


Combine all years for flag and save 
  - need to convert hours to days 
  - need to calculate nv
    -  `nv = nominal_effort / (days_at_sea*mean_engine_p)`

```{r}

days_to_hours_conversion <- qs::qread(here("data/int/hours_to_days_conversion.qs")) %>%
  rename(lon = x, lat = y) %>%
  left_join(global_grid)

nv_conversion <- qs::qread(here("data/model_features/rousseau_ind_effort_nv_conversion.qs"))


data_grid_area <- data_grid_area %>%
st_drop_geometry()

cl <- makeCluster(30) 
registerDoParallel(cl)

foreach(flag = flags_missing, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "UKR"
  
  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions_regional/yearly/"), pattern = flag, full.names = TRUE)
  
    # Skip iteration if no files are found
  if (length(all_files_flag) == 0) next
  
  # hours / hours/day = hours * day/hours = days

  all_data_flag <- lapply(all_files_flag, qread) %>%
    bind_rows() %>%
    left_join(eez_lookup) %>%
    mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
        mutate(eez_country_name = countrycode(eez_sovereign, origin = "iso3c", destination = "country.name")) %>%
    mutate(eez_country_name = ifelse(eez_sovereign == "High seas", "High seas", eez_country_name)) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, flag_country_name, gear, length_category, eez_sovereign, eez_country_name, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours, sector) %>%
        left_join(nv_conversion) %>%
          mutate(nv = nom_active_fishing_hours/(days_at_sea*mean_engine_p)) %>%
    left_join(., days_to_hours_conversion) %>%
    mutate(nom_active_fishing_days = nom_active_fishing_hours/mean,
           eff_active_fishing_days = eff_active_fishing_hours/mean) %>%
    dplyr::select(-mean, -days_at_sea, -mean_engine_p, -p, -gt, -nom_active_days, -eff_active_days) %>%
        rename(flag_country_iso3c = flag_fin, eez_sovereign_iso3c = eez_sovereign, eez_sovereign_name = eez_country_name, fao_fishing_id = fao_id) %>%
    left_join(data_grid_area) %>%
    mutate(pixel_area_km2 = pixel_area_m2/1000000) %>%
    mutate(eff_days_km2 = eff_active_fishing_days/pixel_area_km2,
           nom_days_km2 = nom_active_fishing_days/pixel_area_km2,
           eff_hours_km2 = eff_active_fishing_hours/pixel_area_km2,
           nom_hours_km2 = nom_active_fishing_hours/pixel_area_km2,
           nv_km2 = nv/pixel_area_km2) # calculate hours per km2 here too
  
  qs::qsave(all_data_flag, file.path(rdsi_dir, glue("prep/random_forest/predictions_regional/model_preds_1950_2017_{flag}.qs")))
}

stopCluster(cl)



  all_files_flag <- str_before_first(str_after_last(list.files(file.path(rdsi_dir, "prep/random_forest/predictions_regional/"), pattern = ".qs", full.names = TRUE), "_"), "\\.qs")
  
  setdiff(flags_missing, all_files_flag) # 0 - good

```
