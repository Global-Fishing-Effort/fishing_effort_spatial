---
title: "Download global fishing watch fishing effort: MMSI"
output: html_document
date: "2024-05-14"
---

# Setup

Load packages and directories

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# remotes::install_github("GlobalFishingWatch/gfwr") #install GFW api package

library(gfwr)
library(terra)
library(tidyverse)
library(here)
library(glue)
library(data.table)


source(here("R/dir.R"))


# Save API token information to an object every time you need to extract the token and pass it to `gfwr` functions
# The use of gfwr requires a GFW API token, which users can request from the GFW API Portal. Save this token to your .Renviron file (using usethis::edit_r_environ()) by adding a variable named GFW_TOKEN to the file (GFW_TOKEN = "PASTE_YOUR_TOKEN_HERE"). Save the .Renviron file and restart the R session to make the edit effective.
gages_key <- gfw_api_key <- read.delim(file.path(rdsi_raw_dir, "global_fishing_watch/gfw_api_key.txt")) %>%
  colnames() %>%
  unique() # now add this to usethis::edit_r_environ() and restart R. Only need to do this once? 

# gage's key is saved to gage's .Renviron file, which is read by this function
key <- gfw_auth()

```

# Summary

In this script we download spatialized apparent fishing effort from global fishing watch for all years (2012 - 2020): https://globalfishingwatch.org/data-download/datasets/public-fishing-effort


# Data Sources 

## Global Fishing Watch Apparent Fishing Effort per MMSI

**Reference**:
1. Global Fishing Watch. [2022]. www.globalfishingwatch.org\
2. [`gfwr` API](https://github.com/GlobalFishingWatch/gfwr)

**Downloaded**: June 25, 2024

**Description**: API to extract apparent fishing effort per MMSI (vessel id)

**Native data resolution**: 0.1 degree (maybe 0.01?)

**Time range**: 2012 - 2020

**Format**:  API


# Methods 

Pull apparent fishing effort data for all EEZs for 2012-2020 from the GFW API and save.

 - We've also downloaded the data directly from https://globalfishingwatch.org/data-download/datasets/public-fishing-effort, however, the data from the API is of a higher resolution (0.01 rather than 0.1), so we will download it this way as well. 

## Get list of regions to pull info for

```{r}
## read in fishing vessels info

vessel_info <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/fishing-vessels-v2.csv"))

length(unique(vessel_info$mmsi)) # each row represents a different vessel, so ~115k vessels are tracked

test <- vessel_info %>% 
  filter(is.na(flag_gfw)) 
sum(test$fishing_hours_2020, na.rm = TRUE) # 558320.3 hours
# ~900 vessels missing flag country. 

## can we pull by flag country? 

rgn_list <- vessel_info %>%
  distinct(flag_gfw) %>%
  filter(!is.na(flag_gfw)) %>%
  filter(flag_gfw != "") %>%
  filter(flag_gfw != "CHN") %>% # we will pull china separately bc the data is so large
  pull() %>%
  unique() # 166 flag countries

## maybe we pull the NA flags separately, and can figure out what to do with those later.. not really sure, we'll see

# rgn_list[58:165]
```

## Iterate through and download data

```{r}

years <- c(2012:2020)

## think i will need to do China separately again

## hanging up on FRA, GBR as well; look into RUS

# iterate through all EEZ codes for all regions to extract apparent fishing hours:
for(i in rgn_list[72:165]) {
  
   # i <- rgn_list[[1]]
  
  
  # create dataframe that contains the column `id` that is list of all EEZ codes for one region
  eez_code_df <- get_region_id(region_name = i, region_source = 'eez', key = key) %>%
    filter(!is.na(id))  # there is one NA, bouvet island, need to figure this one out separately
  
  
  # convert that column into a numeric list of EEZ codes to feed into the next loop:
  eez_codes <- eez_code_df$id
  
  
  for(j in eez_codes) { 
   # j = 21787

    sub_region_label = eez_code_df %>% 
      filter(id == j) %>%
      pull(label)
    
    
      print(paste0("Processing apparent fishing hours for ", i, " EEZ code ", j, " ", sub_region_label))


    
    for(y in years){
     # y = 2017
      
          
    if(file.exists(glue(rdsi_raw_dir, "/global_fishing_watch/apparent_fishing_hours_mmsi/{i}_{j}_{y}_annual_effort_grid_highres.csv"))){
          print(paste0("Skipping, file already done"))

      next()
    }
      
    fishing_hours_1 <- gfwr::get_raster(spatial_resolution = 'high', # high = 0.01 degree resolution 
                                      temporal_resolution = 'yearly',
                                      group_by = 'vessel_id',
                                      date_range = glue('{y}-01-01,{y}-04-30'), 
                                      region = j, 
                                      region_source = 'eez',
                                      key = key) %>%
      # rename columns for clarity:
      rename(year = "Time Range",
             apparent_fishing_hours = "Apparent Fishing Hours",
             y = Lat,
             x = Lon,
             geartype = "Gear Type", 
             year = "Time Range",
             vessel_id = "Vessel ID",
             mmsi = MMSI, 
             flag = Flag) %>%
      # keep track of the administrative country for each EEZ, even after we combine all data into one dataframe: 
      mutate(eez_admin_rgn = i,
             sub_rgn_label = sub_region_label,
             gfw_eez_id = j) %>% 
      select(year, apparent_fishing_hours, y, x, eez_admin_rgn, geartype, vessel_id, sub_rgn_label, gfw_eez_id, flag, mmsi)
    
    
      
    
       fishing_hours_2 <- gfwr::get_raster(spatial_resolution = 'high', # high = 0.01 degree resolution
                                      temporal_resolution = 'yearly',
                                      group_by = 'vessel_id',
                                      date_range = glue('{y}-05-01,{y}-08-31'), 
                                      region = j, 
                                      region_source = 'eez',
                                      key = key) %>%
      # rename columns for clarity:
      rename(year = "Time Range",
             apparent_fishing_hours = "Apparent Fishing Hours",
             y = Lat,
             x = Lon,
             geartype = "Gear Type", 
             year = "Time Range",
             vessel_id = "Vessel ID",
             mmsi = MMSI, 
             flag = Flag) %>%
      # keep track of the administrative country for each EEZ, even after we combine all data into one dataframe: 
      mutate(eez_admin_rgn = i,
             sub_rgn_label = sub_region_label,
             gfw_eez_id = j) %>% 
      select(year, apparent_fishing_hours, y, x, eez_admin_rgn, geartype, vessel_id, sub_rgn_label, gfw_eez_id, flag, mmsi)
       
           
       fishing_hours_3 <- gfwr::get_raster(spatial_resolution = 'high', # high = 0.01 degree resolution 
                                      temporal_resolution = 'yearly',
                                      group_by = 'vessel_id',
                                      date_range = glue('{y}-09-01,{y}-12-31'), 
                                      region = j, 
                                      region_source = 'eez',
                                      key = key) %>%
      # rename columns for clarity:
      rename(year = "Time Range",
             apparent_fishing_hours = "Apparent Fishing Hours",
             y = Lat,
             x = Lon,
             geartype = "Gear Type", 
             year = "Time Range",
             vessel_id = "Vessel ID",
             mmsi = MMSI, 
             flag = Flag) %>%
      # keep track of the administrative country for each EEZ, even after we combine all data into one dataframe: 
      mutate(eez_admin_rgn = i,
             sub_rgn_label = sub_region_label,
             gfw_eez_id = j) %>% 
      select(year, apparent_fishing_hours, y, x, eez_admin_rgn, geartype, vessel_id, sub_rgn_label, gfw_eez_id, flag, mmsi)
       
       
    if(nrow(fishing_hours_1) + nrow(fishing_hours_2) + nrow(fishing_hours_3) == 0){
          print(paste0("Skipping, all empty df"))

      next()
    }
       
       fishing_hours <- rbind(fishing_hours_1, fishing_hours_2, fishing_hours_3) %>%
         group_by(year, x, y, eez_admin_rgn, geartype, vessel_id, sub_rgn_label, gfw_eez_id, flag, mmsi) %>%
         summarise(apparent_fishing_hours = sum(apparent_fishing_hours, na.rm = TRUE)) %>%
         ungroup() ## need to split into two because sometimes the api will timeout for certain areas.. this puts less stress on the API
   
## run a test to see if data matches - it does!! So MMSI will be what we want, and I think it is still at 0.01 resolution?      
#  test <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours/GRC_5679_2020_annual_effort_grid_highres.csv"))
# sum(test$apparent_fishing_hours)
# [1] 412047.5
# sum(fishing_hours$apparent_fishing_hours)
# [1] 412047.1
      
    
    # specify column types before saving the csv so we can correctly concatenate the rows later
    fishing_hours$year <- as.numeric(fishing_hours$year)
    fishing_hours$apparent_fishing_hours <- as.numeric(fishing_hours$apparent_fishing_hours)
    fishing_hours$y <- as.numeric(fishing_hours$y)
    fishing_hours$x <- as.numeric(fishing_hours$x)
    fishing_hours$gfw_eez_id <- as.numeric(fishing_hours$gfw_eez_id)
    
    fishing_hours$eez_admin_rgn <- as.character(fishing_hours$eez_admin_rgn)
    fishing_hours$geartype <- as.character(fishing_hours$geartype)
    fishing_hours$sub_rgn_label <- as.character(fishing_hours$sub_rgn_label)
    fishing_hours$flag <- as.character(fishing_hours$flag)
    fishing_hours$vessel_id <- as.character(fishing_hours$vessel_id)

    
    print(paste0("Extracted all apparent fishing hours for ", i, " EEZ code ",j, " ", sub_region_label, " year ", y))
    
    write_csv(fishing_hours, glue(rdsi_raw_dir, "/global_fishing_watch/apparent_fishing_hours_mmsi/{i}_{j}_{y}_annual_effort_grid_highres.csv"))
    
   }
  }
}

## Next we will need to match to the vessel id lookup table, classify into length categories, and save a file for each eez, gear type, and length category? 

```

Compare GFW MMSI and fleet data and Rousseau et al. data

```{r}

test_fleet <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours/CAN_8493_2015_annual_effort_grid_highres.csv"))

test_mmsi <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi/CAN_8493_2015_annual_effort_grid_highres.csv"))

sum(test_fleet$apparent_fishing_hours) # 258414.9

sum(test_mmsi$apparent_fishing_hours) # 256931

## it seems like they are all really close... lets test some more

test_fleet <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours/BGR_5672_2015_annual_effort_grid_highres.csv"))

test_mmsi <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi/BGR_5672_2015_annual_effort_grid_highres.csv"))

sum(test_fleet$apparent_fishing_hours) # 18062.71

sum(test_mmsi$apparent_fishing_hours) # 17871.92


test_fleet <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours/IDN_8492_2015_annual_effort_grid_highres.csv"))

test_mmsi <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi/IDN_8492_2015_annual_effort_grid_highres.csv"))

sum(test_fleet$apparent_fishing_hours) # 2421.68

sum(test_mmsi$apparent_fishing_hours) # 2389.98

## lol OK they're all the same, but obviously this is only industrial... Indonesia has WAY MORE fishing hours than that with small scale fisheries... probably the most in the world

## compare to actual effort from Rousseau: 

imas_effort <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/CapacityCountryLevel_Detailed.csv")
colnames(imas_effort)
unique(imas_effort$Sector)
unique(imas_effort$Country)

imas_idn <- imas_effort %>% 
  filter(Sector == "I",
         Country == "IDN", # is this flag country though? README says "fishing country" so I think it is flag country? That's ok... i think we could still get the info we need from the spatialized version? I.e. hours of effort per EEZ and flag country?
         Year == 2015) 

## compare imas to GFW effort hours
sum(imas_idn$EffActive) # 20608149271
sum(test_mmsi$apparent_fishing_hours) # 2389.98
sum(test_fleet$apparent_fishing_hours) # 2421.68

sum(imas_idn$NVActive) # 43705.35
length(unique(test_mmsi$vessel_id)) # 40
sum(test_fleet$number_of_vessels) # 321

## does not match well at all for Indonesia! Even for industrial fishing sector



```

```{r}


imas_idn <- imas_effort %>% 
  filter(Sector == "I",
         Country == "IDN", # is this flag country though? README says "fishing country" so I think it is flag country? That's ok... i think we could still get the info we need from the spatialized version? I.e. hours of effort per EEZ and flag country?
         Year == 2016) %>%
  group_by(Country,  SAUP) %>%
  summarise(NV = sum(NVActive, na.rm = TRUE),
            EffActive = sum(EffActive, na.rm = TRUE)) %>%
  ungroup()


test_mmsi <- read.csv(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi/IDN_8492_2014_annual_effort_grid_highres.csv"))

all_aggregated_effort <- data.frame(eez_admin_rgn = NA, flag = NA, NV = NA, apparent_fishing_hours = NA, data_type = NA)

for(year in years){
  for(rgn in rgn_list){
    
    # rgn = "IDN"
    # year = 2019
    
    
dir_path <- glue(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi"))

# Construct the filename pattern separately
file_pattern <- glue("{rgn}_.*_{year}_annual_effort_grid_highres.csv")

# Use list.files with the pattern argument
files <- list.files(dir_path, pattern = file_pattern, full.names = TRUE)

this_mmsi <- lapply(files, read.csv) %>%
  bind_rows() %>%
  group_by(eez_admin_rgn, flag) %>%
  summarise(NV = n_distinct(vessel_id),
            apparent_fishing_hours = sum(apparent_fishing_hours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(year = year, 
         data_type = "mmsi")


  }
}

```


```{r}
dir_path <- glue(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours"))

# Construct the filename pattern separately
file_pattern <- glue("{rgn}_.*_{year}_annual_effort_grid_highres.csv")

# Use list.files with the pattern argument
files <- list.files(dir_path, pattern = file_pattern, full.names = TRUE)

this_fleet <- lapply(files, read.csv) %>%
  bind_rows() %>%
  group_by(eez_admin_rgn, flag) %>%
  summarise(NV = sum(number_of_vessels, na.rm = TRUE),
            apparent_fishing_hours = sum(apparent_fishing_hours, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(year = year, 
         data_type = "fleet")
```


Let's prep the data we downloaded directly from GFW, rather than using the API


```{r}

for(year in 2013:2020){
# year = 2012
this_year_files <- list.files(glue("/home/ubuntu/data_storage/raw_data/global_fishing_watch/raw_mmsi_data/mmsi-daily-csvs-10-v2-{year}"), full.names = TRUE)


this_year_df <- lapply(this_year_files, read.csv) %>% 
  bind_rows()

this_year_df_prep <- this_year_df %>%
  mutate(year = year) %>%
  dplyr::select(-date) %>%
  group_by(cell_ll_lat, cell_ll_lon, year, mmsi) %>%
  summarise(hours = sum(hours, na.rm = TRUE),
            fishing_hours = sum(fishing_hours, na.rm = TRUE)) %>%
  ungroup() %>%
  left_join(vessel_info, by = "mmsi")

fwrite(this_year_df_prep, file.path(rdsi_raw_dir, glue("global_fishing_watch/raw_mmsi_data/prepped_data/all_effort_{year}.csv")), row.names = FALSE)

}


test <- this_year_df_prep %>%
  filter(flag_gfw == "USA") # ok there actually isn't any data in IDN until 2014... so this is a technology adoption problem probably 

sum(test$fishing_hours) # 475357
test %>% distinct(mmsi, fishing_hours_2012) %>% pull(fishing_hours_2012) %>% sum() # 475356.9 - cool - matches almost perfectly

test2 <- this_year_df_prep %>% 
  group_by(flag_gfw, vessel_class_gfw) %>% 
  summarise(fishing_hours = sum(fishing_hours, na.rm = TRUE)) %>%
  ungroup()

test3 <- this_year_df_prep %>%
  filter(is.na(flag_gfw)) # might need to assume that this fishing flag country is just whatever eez it is occuring in 

```


To do a random forest to identify the best predictors of prescence/absense of fishing we need:

 - High, low, and medium income country example. Best tracked examples are in Europe (~61% industrial vessels tracked)
    - will need file that matches cell to iso3c
    - China has ~40% tracked, UK ~60% tracked, KOR ~40% tracked: https://figshare.com/articles/journal_contribution/Satellite_mapping_reveals_extensive_industrial_activity_at_sea_-_analysis_data/24309475?file=44031627; https://www.nature.com/articles/s41586-023-06825-8/figures/9
 - oceanographic data: SST, depth, chlorophyll
     - Bathymetry (depth): https://www.gebco.net/data_and_products/gridded_bathymetry_data/
       - GFW also has bathymetry data... will use this since it is already prepped and way smaller
 - cell information: Distance to closest port, distance to shore (these might be difficult to calculate?)
    - GFW has distance to port on a 1km grid: https://globalfishingwatch.org/data-download/datasets/public-distance-from-port-v1
    - distance to nearest coastline on 0.01 degree grid: https://www.pacioos.hawaii.edu/metadata/dist2coast_1deg_ocean.html
    - GFW also provides distance to shore on 1km grid: https://globalfishingwatch.org/data-download/datasets/public-distance-from-shore-v1
 - vessel info: gear, target spp, etc. But this might just over represent data, so not sure this would make sense 


