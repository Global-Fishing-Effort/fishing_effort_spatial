---
title: "Predict props to cells per flag, year, gear, length"
output: html_document
date: "2024-12-11"
---

# Summary

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(terra)
library(foreach)
library(doParallel)
library(progress)
library(pryr)  # for memory tracking
library(glue)
library(qs)
library(here)
library(randomForest)
library(janitor)
library(arrow)
library(countrycode)

source(here("R/dir.R"))
```

## Functions to prepare enviro and effort data  

```{r}

elnino <- read.csv(here("data/model_features/enso_index.csv"))

pdo <- read.csv(here("data/model_features/pdo_index.csv"))

world_bank <- read.csv(here("data/model_features/world_bank_regions.csv")) %>%
  filter(ISO_SOV1 != "GIB") # filter out gibralter bc it is duplicating the UK for some reason

gfi_df <- read.csv(here("data/model_features/global_fishing_index_governance.csv"))
  
# Load prepared data
model_data <- readRDS(here("data/model_features/prepared_data_1deg.rds")) %>%
  mutate(year = as.numeric(year)) # i think we need to adjust the prepared data to include cells which have no fishing effort in them. We can do this in the loop below? 

## read in environmental variables

  global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv"))
  
  ocean_data <- read.csv(here("data/model_features/deg_1_x_1/errdap_chl.csv")) %>%
  left_join(read.csv(here("data/model_features/deg_1_x_1/errdap_sst.csv")), by = c("pixel_id", "year")) %>% 
  left_join(read.csv(here("data/model_features/deg_1_x_1/remss_wind.csv")), by = c("pixel_id", "year")) %>%
  filter(year %in% c(2015:2017)) %>%
  dplyr::select(-anom_sst_c_mean, -anom_sst_c_sd)
  
  ocean_data_historical <- qs::qread(here("data/int/prediction_historical_data/chl_yearly_1950_2014.qs")) %>%
  left_join(qs::qread(here("data/int/prediction_historical_data/sst_yearly_1950_2014.qs")), by = c("pixel_id", "year")) %>% 
  left_join(qs::qread(here("data/int/prediction_historical_data/wind_yearly_1950_2014.qs")) %>% mutate(year = as.numeric(year)), by = c("pixel_id", "year"))

  ocean_data_all <- ocean_data %>%
    rbind(ocean_data_historical)

  spatial_data <- global_grid %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/gfw_static_spatial_measures.csv")) %>% dplyr::select(-lat, -lon), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/mesopelagiczones/mesopelagiczones_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/eez/eez.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/fao/fao_fixed.csv")), by = "pixel_id") %>%
   left_join(read.csv(here("data/model_features/deg_1_x_1/oceans_fixed.csv")), by = "pixel_id") %>%
    left_join(read.csv(here("data/model_features/deg_1_x_1/seamounts.csv")), by = "pixel_id") %>% 
   crossing(., year = c(1950:2017)) 
  
  
  env_data <- spatial_data %>%
    left_join(ocean_data_all) %>% # cool.
    left_join(elnino) %>%
    left_join(pdo) %>%
    left_join(world_bank, by = c("eez_id" = "MRGID_SOV1")) %>%
    mutate(eez_region_world_bank_7 = ifelse(ISO_SOV1 %in% c("High seas", "Land"), "High seas", eez_region_world_bank_7)) %>% 
    left_join(gfi_df, by = c("ISO_SOV1" = "flag_fin")) %>% # add in global fishing index data here
    mutate(gov_score = ifelse(eez_id >= 99999 & is.na(gov_score), "high_seas", gov_score)) %>%
        mutate(gov_score = ifelse(eez_id < 99999 & is.na(gov_score), "no_data", gov_score)) %>%
    dplyr::select(-ISO_SOV1, -nearest_seamount_id) %>% 
    distinct()  %>%
    dplyr::select(-geometry_wkt)



```

```{r}

  hist_fish_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    dplyr::select(flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name"))

  
flags <- unique(hist_fish_data$flag_fin) # get the flags we need to run models for # 147 of them

unique_combinations <- hist_fish_data %>%
  distinct(year, flag_fin, gear, length_category) %>% # we only want to make models for these combinations since these are what is in the IMAS/FAO data 
  mutate(row_n = row_number())


env_grid <- env_data %>% 
  dplyr::select(lon, lat) %>% distinct()

full_model_formula <- formula(
  prop_fishing_hours_cell ~ 
    # Categorical/factor predictors
    gear  + 
    length_category +
    meso_id +  
    eez_id + 
    fao_id + 
    ocean +  # Spatial categorical variables
    eez_region_world_bank_7 + # world bank regions
    gov_score + # global fishing index; make sure this is character and not a numeric variable
    # Total effort predictor (log-transformed)
  #  log_total_fishing_hours + 
    # Continuous predictors
    lon + lat + 
    elevation_m + # depth
    distance_from_port_m + 
    distance_from_shore_m +
    chl_mg_per_m3_mean + 
    chl_mg_per_m3_sd +
    sst_c_mean + 
    sst_c_sd +
    wind_speed_ms_mean + 
    wind_speed_ms_sd +
    enso_index_mean + # el nino data 
    enso_index_sd + # pacific decadal oscillation
    pdo_index_mean +  
    pdo_index_sd + 
    nearest_seamount_distance_m + 
    # Year effect
    year
)

```


Read in EEZ id and FAO id lookup tables so we can save with the actual iso3c and FAO id numbers

```{r}

eez_lookup <- read.csv(here("data/model_features/deg_1_x_1/eez/eez_lookup.csv")) %>%
  clean_names() %>%
  mutate(eez_country_name = countrycode(eez_sovereign, origin = "iso3c", destination = "country.name")) %>%
  mutate(eez_country_name = ifelse(is.na(eez_country_name), "High seas", eez_country_name))


fao_lookup <- read.csv(here("data/model_features/deg_1_x_1/fao/fao_major_ids.csv")) %>%
  clean_names() %>%
  dplyr::select(fao_id, "fao_major_fishing_area" = "name_en")

global_grid <- read.csv(here("data/model_features/deg_1_x_1/global_grid.csv")) %>%
  dplyr::select(lon, lat, pixel_id)

```



After the models are fit, we make predictions on ALL DATA. So stage 1 is in sample predictions (since we fit the stage one model on all data), and stage two will contain out of sample predictions (since we fit the model on only data with fishing effort in it!)

```{r}

access_data <- qs::qread(here("data/int/prediction_historical_data/fishing_access.qs"))
access_data_high_seas <- qs::qread(here("data/int/prediction_historical_data/high_seas_fao_fishing_access.qs")) %>%
  rename(fao_id = fao_area)

## out of sample predictions for CHN 
env_grid <- env_data %>% 
  dplyr::select(lon, lat) %>% distinct()


stage_1_path <- file.path(rdsi_dir, "prep/random_forest/stage_1_models/")
stage_1_files <- list.files(stage_1_path, full.names = TRUE)
stage_1_flags <- unique(sub(".*stage_1_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_1_files))[-1] # 118 flags; weird there are more here than in stage 2?!


stage_2_path <- file.path(rdsi_dir, "prep/random_forest/stage_2_models/")
stage_2_files <- list.files(stage_2_path, full.names = TRUE)
stage_2_flags <- unique(sub(".*stage_2_rf_model_full_data_([A-Z]{3})_.*", "\\1", stage_2_files))[-1] # 118 flags; weird there are more here than in stage 2?!

diff_flags_1 <- setdiff(stage_1_flags, stage_2_flags)
diff_flags_2 <- setdiff(stage_2_flags, stage_1_flags)

model_flags <- intersect(stage_1_flags, stage_2_flags)


years <- c(1950:2017)

cl <- makeCluster(15)  # could probably increase this? It takes ~1 hour with 10 cores
registerDoParallel(cl)

foreach(flag = model_flags, .packages = c("dplyr", "tidyverse", "randomForest", "qs", "glue")) %dopar% {
  # flag = "LTU"
  for(yr in years) {
    
   # if(file.exists(file.path(rdsi_dir, glue("prep/random_forest/predictions/yearly/model_preds_{flag}_{yr}.qs")))){
   #   cat("skipping", "exists")
   #   next()
   # }

# flag = "BGR"
# yr = 1990

    ## test out AGO, 2017, Lines_Longlines, 12-24m; see if the prediction will work? 
  
# model_data_flag <- model_data %>%
#   dplyr::select(lon, lat, flag_fin, gear, length_category, year, prop_fishing_hours_cell) %>%
#   filter(flag_fin == flag, year == yr)
#   
# distinct_cats <- model_data_flag %>%
#     distinct(flag_fin, gear, length_category) 

# get combination of categories we need to run through our models
model_data_flag <- hist_fish_data %>%
  dplyr::select(flag_fin, gear, length_category, year, total_nominal_fishing_hours ) %>%
  filter(flag_fin == flag, year == yr)
  
distinct_cats <- model_data_flag %>%
    distinct(flag_fin, gear, length_category) 

# distinct_cats <- data.frame(flag_fin = "AGO", gear = "Lines_Longlines", length_category = "12-24m")
  
full_grid <- tidyr::crossing(env_grid, distinct_cats) %>%
  crossing(., year = yr)
  
full_data <- full_grid %>%
  left_join(env_data, by = c("lon", "lat", "year")) %>%
  dplyr::select(-pixel_id) 

if(nrow(full_data) == 0){
    cat("skipping", flag, yr, "check to make sure this is right")
  next()
}

# read in stage 2 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/stage_2_models/"), 
  pattern = glue::glue("stage_2_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage2_model <- qs::qread(matching_files[1])  # Read the first matching file
} else {
  stop("No matching file found for flag: ", flag)
}

set.seed(123)
oos_preds <- full_data %>%
  mutate(pred_prop = predict(stage2_model, newdata = ., type="response")) 

## read in stage 1 model! 
# Get the list of matching files
matching_files <- list.files(
  path = file.path(rdsi_dir, "prep/random_forest/stage_1_models/"), 
  pattern = glue::glue("stage_1_rf_model_full_data_{flag}_.*\\.qs$"),
  full.names = TRUE
)

# Check if a matching file exists
if (length(matching_files) > 0) {
  stage1_model <- qs::qread(matching_files[1])  # Read the first matching file
} else {
  stop("No matching file found for flag: ", flag)
}

set.seed(123)
stage1_preds <- full_data %>%
    mutate(pred_presence = predict(stage1_model, newdata = ., type="prob")[, "1"]) 


# varImpPlot(stage1_model)
# 
# stage1_2015 <- stage1_preds %>% 
#   filter(year == 2015)
# plot(stage1_2015$distance_from_port_m, stage1_2015$pred_presence)
# 
# imp <- importance(stage1_model)
# impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
# 
# pdpdata <- partialPlot(stage1_model, model.frame(full_data %>% na.omit()), "distance_from_shore_m", xlab = "distance_from_shore_m", main = "Partial Dependence on distance from shore", which.class = 1)
# 
# pdpdata$y <- exp(pdpdata$y) / (1 + exp(pdpdata$y))  # Convert log-odds to probability
# plot(pdpdata$x, pdpdata$y, type = "l")


stage_1_preds_rescale <- stage1_preds %>%
  group_by(flag_fin, gear, length_category) %>%
  mutate(max_pred = max(pred_presence, na.rm = TRUE)) %>%
  ungroup() %>%
  left_join(eez_lookup) %>%
  mutate(pred_presence = case_when( # adding this so that we will have predictions even if the maximum prob is < 0.5, but only assigning 1 in these cases when the flag country is fishing in their EEZ
    max_pred < 0.5 & pred_presence > 0 & flag_fin == eez_sovereign | max_pred < 0.5 & pred_presence > 0 & flag_fin == "TWN" & eez_sovereign == "CHN" ~ 1,
    max_pred >= 0.5 & pred_presence >= 0.5 ~ 1,
    TRUE ~ 0
  )) %>%
  dplyr::select(-max_pred)



## join stage 1 and 2 preds together and multiply 
all_preds <- oos_preds %>%
  dplyr::select(lat, lon, gear, length_category, year, flag_fin, pred_prop) %>% # probably select lat, lon, gear, length, year, flag here?
  left_join(., stage_1_preds_rescale) %>% 
    dplyr::select(lon, lat, flag_fin,gear, length_category, year, fao_id, eez_id, eez_sovereign, eez_country_name, pred_prop, pred_presence) %>% 
  left_join(access_data %>% dplyr::select(-eez_sovereign)) %>%
  left_join(access_data_high_seas) %>%
  mutate(access = ifelse(is.na(access), 0, access),
         access_fao = ifelse(is.na(access_fao), 0, access_fao)) %>% # only allow fishing where Rousseau says they can fish
  mutate(access = ifelse(eez_sovereign == flag, 1, access)) %>% # always allow a country to fish in its own EEZ
  mutate(access_fin = ifelse(eez_country_name == "High seas", access_fao, access)) %>% # only allow fishing in fao areas where Rousseau they can fish in the high seas
  mutate(pred_prop_final = pred_prop*pred_presence*access_fin) %>%
  filter(pred_prop_final > 0) %>%
  filter(!is.na(pred_prop_final)) %>%
 group_by(year, flag_fin, gear, length_category) %>%
  mutate(prop_fishing_hours_cell_predict_rescaled = pred_prop_final / sum(pred_prop_final, na.rm = TRUE)) %>%
 ungroup() %>% # need to rescale the predictions to be between 0 and 1 here so that we can allocate effort
  left_join(hist_fish_data) %>%
  mutate(nom_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_nominal_fishing_hours,
         eff_active_fishing_hours = prop_fishing_hours_cell_predict_rescaled*total_effective_fishing_hours) %>%
  left_join(global_grid) %>%
  left_join(fao_lookup) %>%
  left_join(eez_lookup) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, gear, length_category, eez_sovereign, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours) %>%
  filter(nom_active_fishing_hours > 0) %>%
  mutate(sector = "Industrial")

if(nrow(all_preds) == 0){
    cat("skipping", flag, yr, "no predictions made...")
  next()
}

# test_preds <- all_preds %>%
#   filter(gear == "Dredges") %>%
#   #filter(eez_sovereign != "High seas") %>%
#   dplyr::group_by(lon, lat) %>%
#   summarise(nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
#   ungroup() %>%
#   rast(., type = "xyz")
# 
# plot(test_preds)
# plot(log(test_preds+1)) # Cool!

# test <- all_preds %>% 
#    group_by(year, flag_fin, gear, length_category) %>%
#   mutate(total_nom =  sum(nom_active_fishing_hours, na.rm = TRUE)) %>%
#   ungroup() %>%
#   right_join(hist_fish_data)

qs::qsave(all_preds, file.path(rdsi_dir, glue("prep/random_forest/predictions/yearly/model_preds_{flag}_{yr}.qs"))) # qs is smaller

  }

}

stopCluster(cl)


```

Combine all years for flag and save 

```{r}

days_to_hours_conversion <- qs::qread(here("data/int/hours_to_days_conversion.qs")) %>%
  rename(lon = x, lat = y) %>%
  left_join(global_grid)

cl <- makeCluster(20)  # could probably increase this? 
registerDoParallel(cl)

foreach(flag = model_flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "ARG"
  
  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions/yearly/"), pattern = flag, full.names = TRUE)
  
    # Skip iteration if no files are found
  if (length(all_files_flag) == 0) next
  

  all_data_flag <- lapply(all_files_flag, qread) %>%
    bind_rows() %>%
    left_join(eez_lookup) %>%
    mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, flag_country_name, gear, length_category, eez_sovereign, eez_country_name, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours, sector) %>%
    left_join(., days_to_hours_conversion) %>%
    mutate(nom_active_fishing_days = nom_active_fishing_hours/mean,
           eff_active_fishing_days = eff_active_fishing_hours/mean) %>%
    dplyr::select(-mean) %>%
        rename(flag_country_iso3c = flag_fin, eez_sovereign_iso3c = eez_sovereign, eez_sovereign_name = eez_country_name, fao_fishing_id = fao_id)
  
  
  qs::qsave(all_data_flag, file.path(rdsi_dir, glue("prep/random_forest/predictions/model_preds_1950_2017_{flag}.qs")))
}

stopCluster(cl)

```

Save csv files to upload to Zenodo

```{r}

days_to_hours_conversion <- qs::qread(here("data/int/hours_to_days_conversion.qs")) %>%
  rename(lon = x, lat = y) %>%
  left_join(global_grid)

cl <- makeCluster(20)  # could probably increase this? 
registerDoParallel(cl)

foreach(flag = model_flags, .packages = c("qs", "dplyr", "tidyverse", "glue", "countrycode")) %dopar% {
  # flag = "USA"
  
  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/predictions/yearly/"), pattern = flag, full.names = TRUE)
  
    # Skip iteration if no files are found
  if (length(all_files_flag) == 0) next
  

  all_data_flag <- lapply(all_files_flag, qread) %>%
    bind_rows() %>%
    left_join(eez_lookup) %>%
    mutate(flag_country_name = countrycode(flag_fin, origin = "iso3c", destination = "country.name")) %>%
    dplyr::select(pixel_id, lon, lat, year, flag_fin, flag_country_name, gear, length_category, eez_sovereign, eez_country_name, fao_id, fao_major_fishing_area, nom_active_fishing_hours, eff_active_fishing_hours, sector) %>%
    left_join(., days_to_hours_conversion) %>%
    mutate(nom_active_fishing_days = nom_active_fishing_hours/mean,
           eff_active_fishing_days = eff_active_fishing_hours/mean) %>%
    dplyr::select(-mean, -pixel_id) %>%
        rename(flag_country_iso3c = flag_fin, eez_sovereign_iso3c = eez_sovereign, eez_sovereign_name = eez_country_name, fao_fishing_id = fao_id)
  
  
  write.csv(all_data_flag, file.path(rdsi_dir, glue("prep/random_forest/zenodo_data/mapped_by_flag_country/model_preds_1950_2017_{flag}.csv")), row.names = FALSE)
}

stopCluster(cl)

## save as one large csv

  all_files_flag <- list.files(file.path(rdsi_dir, "prep/random_forest/zenodo_data/mapped_by_flag_country/"), full.names = TRUE)

    all_data <- lapply(all_files_flag, read.csv) %>%
      bind_rows()
    
    
write.csv(all_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/mapped_industrial_effort_predictions_1950_2017.csv"), row.names = FALSE)

test <- all_data %>% 
  filter(flag_country_iso3c == "BGR", year == 1990)

all_data_grouped <- all_data %>% 
  group_by(year, flag_country_iso3c, flag_country_name, gear, length_category, eez_sovereign_iso3c, eez_sovereign_name, fao_fishing_id, fao_major_fishing_area, sector) %>%
  summarise(eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE)) %>%
  ungroup()


write.csv(all_data_grouped, file.path(rdsi_dir, "prep/random_forest/zenodo_data/industrial_effort_predictions_by_flag_eez_fao_gear_length_1950_2017.csv"), row.names = FALSE)

all_data_grouped_2 <- all_data_grouped %>% 
  group_by(year, flag_country_iso3c, flag_country_name, gear, length_category) %>%
    summarise(modeled_eff_active_fishing_hours = sum(eff_active_fishing_hours, na.rm = TRUE), 
            modeled_eff_active_fishing_days = sum(eff_active_fishing_days, na.rm = TRUE), 
            modeled_nom_active_fishing_hours = sum(nom_active_fishing_hours, na.rm = TRUE), 
            modeled_nom_active_fishing_days = sum(nom_active_fishing_days, na.rm = TRUE)) %>%
  ungroup()

hist_fish_data <- qs::qread(here("data/int/rousseau_gear_fix.qs")) %>%
    ## remove artisanal
    filter(sector == "I") %>%
    group_by(year, flag_fin = country, gear = gear_new, length_category) %>%
    summarize(
      total_nominal_fishing_hours = sum(nom_active_hours, na.rm = TRUE),
      total_effective_fishing_hours = sum(eff_active_hours, na.rm = TRUE),
      total_nominal_fishing_days = sum(nom_active, na.rm = TRUE),
      total_effective_fishing_days = sum(eff_active, na.rm = TRUE)
    ) %>%
  ungroup() %>%
    dplyr::select(flag_country_iso3c = flag_fin, year, gear, length_category, total_nominal_fishing_hours, total_effective_fishing_hours, total_nominal_fishing_days, total_effective_fishing_days) %>%
        filter(total_nominal_fishing_hours > 0) %>%
  mutate(flag_country_name = countrycode(flag_country_iso3c, origin = "iso3c", destination = "country.name")) %>%
  left_join(all_data_grouped_2) %>%
  mutate(modeled_eff_active_fishing_hours = ifelse(is.na(modeled_eff_active_fishing_hours), 0, modeled_eff_active_fishing_hours),
         modeled_eff_active_fishing_days = ifelse(is.na(modeled_eff_active_fishing_days), 0, modeled_eff_active_fishing_days), 
         modeled_nom_active_fishing_hours = ifelse(is.na(modeled_nom_active_fishing_hours), 0, modeled_nom_active_fishing_hours),
         modeled_nom_active_fishing_days = ifelse(is.na(modeled_nom_active_fishing_days), 0, modeled_nom_active_fishing_days)) %>%
  mutate(proportion_hours_modeled = modeled_nom_active_fishing_hours/total_nominal_fishing_hours)


missing_data <- hist_fish_data %>%
  filter(proportion_hours_modeled == 0)

write.csv(hist_fish_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/known_industrial_effort_rousseau.csv"), row.names = FALSE)


write.csv(missing_data, file.path(rdsi_dir, "prep/random_forest/zenodo_data/effort_not_modelled.csv"), row.names = FALSE)

```



Actual CHN, trawlers, 12-24m, 2015 data

```{r}

saup <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/SAUPtoCountry.csv") %>%
  dplyr::select(-X)
test <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/TotalEffortby_FishingCountry_LengthBoat_Gear_Sector.csv") %>%
  filter(Sector == "I", 
         Gear == "Trawl_Midwater_or_Unsp") %>%
  dplyr::select(-X) %>%
  left_join(saup) %>%
  filter(Country == "IRN", 
         Year == 2017)
 


test <- read.csv("https://data.imas.utas.edu.au/attachments/1241a51d-c8c2-4432-aa68-3d2bae142794/TotalEffortby_FishingCountry_LengthBoat_Gear_Sector.csv") %>%
  filter(Sector == "I") %>%
  dplyr::select(-X) %>%
  group_by(Year) %>%
  summarise(NomActive = sum(NomActive, na.rm = TRUE), 
            EffActive = sum(EffActive, na.rm = TRUE)) %>%
  ungroup()

ggplot(test, aes(x = Year, y = NomActive)) + 
        geom_line()

ggplot(test, aes(x = Year, y = EffActive)) + 
        geom_line()
 

    test_gfw_raw <- qs::qread(file.path(rdsi_raw_dir, "global_fishing_watch/apparent_fishing_hours_mmsi/v2_aggregated/all_effort_2015.qs")) %>%
      filter(flag_gfw == "CHN", 
             vessel_class_gfw == "trawlers",
             length_m_gfw <=24 & length_m_gfw >=12) %>%
  group_by(cell_ll_lon, cell_ll_lat) %>%
  summarise(total_hours = sum(fishing_hours, na.rm = TRUE)) %>% 
  ungroup()

test_rast <- test_gfw_raw %>%
  rast(., type = "xyz")
plot(test_rast, col = "green")
plot(test_rast)


    test_gfw_prep <- qs::qread(file.path(rdsi_dir, "prep/gfw_props/deg_one/all_effort_gear_length_props_2015.qs")) %>%
      filter(flag_fin == "CHN", 
             gear == "Trawl_Midwater_or_Unsp",
             length_category == "Over 50m") %>%
  group_by(x, y) %>%
  summarise(total_hours = sum(fishing_hours, na.rm = TRUE)) %>% 
  ungroup()

test_rast <- test_gfw_prep %>%
  rast(., type = "xyz")
plot(test_rast, col = "green")
plot(test_rast)



```

